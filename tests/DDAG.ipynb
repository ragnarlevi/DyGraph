{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys,os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_t as mvt, norm, multivariate_normal\n",
    "import sklearn\n",
    "from sklearn.covariance import GraphicalLasso\n",
    "import scipy\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "import time\n",
    "import tqdm\n",
    "import networkx as nx\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': 25,\n",
    "         'axes.labelsize': 25,\n",
    "         'axes.titlesize':25,\n",
    "         'xtick.labelsize':25,\n",
    "         'ytick.labelsize':'x-large',\n",
    "          'axes.titlesize' : 'x-large'}\n",
    "pylab.rcParams.update(params)\n",
    "sys.path.insert(0, 'C:/Users/User/Code/DyGraph')\n",
    "\n",
    "import DyGraph as dg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate DAG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.033763808268411"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_per_graph = 1000\n",
    "X = np.zeros((obs_per_graph, 5))\n",
    "sigma = 0.1\n",
    "rnd = np.random.RandomState(42)\n",
    "\n",
    "A  = np.array([[0,0,0,0,0],\n",
    "                [0.4, 0.0,0,0,0], \n",
    "                [0,0.35 , 0.0, 0,0], \n",
    "                [0.0, 0.0, 0.5, 0,0],\n",
    "                [0, 0, 0, 0.3, 0]])\n",
    "\n",
    "I = np.identity(X.shape[1])\n",
    "\n",
    "W = np.linalg.inv(I-A)\n",
    "\n",
    "for i in range(obs_per_graph):\n",
    "    # X[i,0] =  rnd.normal(0,1)\n",
    "    # X[i,1] = np.dot(W[1], X[i]) + rnd.normal(0,1)\n",
    "    # X[i,2] = np.dot(W[2], X[i]) + rnd.normal(0,1)\n",
    "    # X[i,3] = np.dot(W[3], X[i]) + rnd.normal(0,1)\n",
    "    # X[i,4] = np.dot(W[4], X[i]) + rnd.normal(0,1)\n",
    "\n",
    "    X[i] = np.dot(A+I, np.random.normal(0,1,5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "I = np.identity(X.shape[1])\n",
    "np.linalg.cond(W)\n",
    "# for i in range(obs_per_graph):\n",
    "#     X[i,1] = rnd.normal(0,1)\n",
    "#     X[i,2] = 0.5*X[i,1] + rnd.normal(0,1)\n",
    "#     X[i,3] = 0.2*X[i,1] + rnd.normal(0,1)\n",
    "#     X[i,4] = 0.25*X[i,2] + 0.1*X[i,3] + rnd.normal(0,1)\n",
    "#     X[i,0] =  0.3*X[i,3] + rnd.normal(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.2  , 1.   , 0.   , 0.   , 0.   ],\n",
       "       [0.06 , 0.3  , 1.   , 0.   , 0.   ],\n",
       "       [0.03 , 0.15 , 0.5  , 1.   , 0.   ],\n",
       "       [0.009, 0.045, 0.15 , 0.3  , 1.   ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I + A + np.dot(A,A) + np.dot(A,A).dot(A)  + np.dot(A,A).dot(A).dot(A) + np.dot(A,A).dot(A).dot(A).dot(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9186185569575491"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.cond(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.2  , 1.   , 0.   , 0.   , 0.   ],\n",
       "       [0.06 , 0.3  , 1.   , 0.   , 0.   ],\n",
       "       [0.03 , 0.15 , 0.5  , 1.   , 0.   ],\n",
       "       [0.009, 0.045, 0.15 , 0.3  , 1.   ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApQAAAHzCAYAAACe1o1DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/z0lEQVR4nO3de2DPdf//8cfn89mGzXGb5bSZc2h1VUR1UVL6Xpfyu3QUSiVFIQrhqqurNhMmQoSkEukgRTroIOmEq+jCVXze2EYOs+3CDmz77PP+/VG6yGnzObw/h/vtn+Tz2ev92NL28Pq8X8+PzTRNUwAAAMA5slsdAAAAAMGNQgkAAACPUCgBAADgEQolAAAAPEKhBAAAgEcolAAAAPAIhRIAAAAeoVACAADAIxRKAAAAeIRCCQAAAI9QKAEAAOARCiUAAAA8QqEEAACARyiUAAAA8AiFEgAAAB6hUAIAAMAjFEoAAAB4hEIJAAAAj1AoAQAA4BEKJQAAADxCoQQAAIBHKJQAAADwCIUSAAAAHqFQAgAAwCMUSgAAAHiEQgkAAACPUCgBAADgEQolAAAAPEKhBAAAgEcolAAAAPAIhRIAAAAeoVACAADAIxRKAAAAeIRCCQAAAI9QKAEAAOARCiUAAAA8QqEEAACARyKsDgAAABBsikpcyswrUqnLragIu5LjYhRTJXxrVfh+5gAAAJXg3F+ghWuztWprjrLzi2Ue95hNUlJstLq0SlCfDklqcV4Nq2Jawmaapnn2pwEAAISnXfnFGrt0k9YYuXLYbSp3n746HXu8U/N4pfdMUWJstB+TWodCCQAAcBqL12fryWVb5HKbZyySf+Sw2xRht+mpHm3Vq32SDxMGBgolAADAKcxY5VTGym0erzOiW0sN7tLCC4kCF6e8AQAA/mDx+myvlElJyli5TW+sz/bKWoGKQgkAAHCcXfnFenLZFq+u+Y9lW7Qrv9irawYSCiUAAMBxxi7dJFcl7pesCJfb1Nilm7y6ZiChUAIAAPzGub9Aa4zcSh3AqYhyt6k1Rq6MnAKvrhsoKJQAAAC/Wbg2Ww67zSdrO+w2vfZdaN5LSaEEAAD4zaqtOV7fnTym3G1q1bYcn6xtNQolAACApMISl7J9fHAmO69YRSUun17DChRKAAAASVl5RfL1cG5TUmZekY+v4n8USgAAAEmlLndIXcefKJQAAACSoiL8U4v8dR1/Cr3PCAAA4Bwkx8XIN+e7/8f223VCDYUSAABAUkyVCCXFRvv0Gklx0YqpEuHTa1iBQgkAAPCbLq0SfDqHskvLBJ+sbTUKJQAAwG/6dEjy6RzKvh2TfLK21SiUAAAAv2lxXg11ah7v9V1Kh92mTs3j1TyhhlfXDRQUSgAAgOOk90xRhJcLZYTdpvSeKV5dM5BQKAEAAI6TGButp3q09eqaT/doq0QfH/ixEoUSAADgD3q1T9KIbi29stbIbq10e/vQvHfyGJtpmr5+lyEAAICgtHh9tp5ctkWlZS6ZtorvwznsNkXYbXq6R9uQL5MShRIAAOCMvv33NvUc/6aqJl8sh912xlPgxx7v1Dxe6T1TQvpl7uOF3mRNAAAAL3pl5rNyf/aO3lu3WUv/fUCf/7xP2flHJNv/Du7Y9OvQ8i4tE9S3Y1LInuY+HQolAADAaezevVvz58/X008/rYuSE3RRcoJ+XpSqr955T/cNH6NBDw1RVIRdyXExIfkOOBXFS94AAACnMXToUC1cuFCZmZmqUaOGPv30U1133XWSpMsuu0xr1661OGFg4JQ3AADAKezbt09z587VsGHDVKNGDR08eFB33nmnbL+91L1+/Xrt2bPH4pSBgUIJAABwChkZGYqKitKQIUMkSQ899JAOHDig41/cXbJkiVXxAgqFEgAA4A8OHDigWbNmaejQoapdu7aWLl2qRYsWqby8/ITnvf766xYlDCwUSgAAgD949tlnZbfbNWzYMEm/Hs6JjIw86Xnffvut9u3b5+d0gYdDOQAAAMfJz89X48aN9eCDD2rChAm//355ebl++uknpaSk6J577lFsbKwOHTqkKVOmqHr16hYmtl74nm8HAAA4heeee07l5eV69NFHT/h9h8Oh0tJSSdLAgQN12WWXWREvIPGSNwAAwG8OHTqk5557TgMHDlRCQsJJjxuGIUlq0aKFv6MFNAolAADAb2bMmKGjR49q5MiRp3zcMAzFxsaqTp06fk4W2CiUAAAAkgoLCzVlyhTdd999ql+//imfYxiGmjdv7udkgY9CCQAAIGnWrFk6fPiwHnvssdM+x+l0UihPgUIJAADCXnFxsTIyMnT33XcrMTHxtM8zDIP7J0+BQgkAAMLenDlzlJeXp9GjR5/2OYWFhdq3bx87lKdAoQQAAGHt6NGjmjhxovr27aumTZue9nnHTnhTKE9GoQQAAGHtpZde0v79+zV27NgzPo+RQadHoQQAAGGrtLRUzzzzjHr16qWWLVue8bmGYah27dqKjY31U7rgQaEEAABh69VXX9Xu3bv197///azPPTYyyGaz+SFZcKFQAgCAsORyuTR+/HjdfPPNatOmzVmfz8ig0+O9vAEAQFhatGiRduzYoXfeeadCzzcMQ1dddZWPUwUndigBAEDYKS8v17hx49SjRw9ddNFFZ31+UVGR9uzZww7labBDCQAAws6bb76pbdu2aeHChRV6/vbt2yUxMuh02KEEAABhxe12a9y4cfrLX/6idu3aVehjGBl0ZuxQAgCAsLJ06VJt2bJFc+fOrfDHGIahmjVrKj4+3ofJghc7lAAAIGyYpqm0tDR17dpVl19+eYU/jpFBZ8YOJQAACBvvv/++Nm7cqC+++KJSH8fIoDNjhxIAAIQF0zSVmpqqTp06VXr8j2EY3D95BuxQAgCAsPDxxx9r/fr1WrlyZaU+7siRI9q9ezc7lGfADiUAAAh5x3YnO3TooGuvvbZSH8vIoLNjhxIAAIS8VatW6ZtvvtH7779f6YM1jAw6O3YoAQBAyEtNTdUll1yiv/71r5X+WMMwVL16dSUkJPggWWhghxIAAIS0r776Sl988YWWLl16TmN/GBl0djbTNE2rQwAAAPjK9ddfr71792rjxo2y2yv/4mzXrl0VGxurt956ywfpQgMveQMAgJC1du1arVy5Uo8//vg5lUmJkUEVQaEEAAAhKzU1Veeff75uvvnmc/r4o0ePateuXZzwPgvuoQQAACHphx9+0IoVK7RgwQI5HI5zWmPHjh0yTZNCeRbsUAIAgJCUlpamZs2aqVevXue8BiODKoYdSgAAEHI2bdqkpUuXat68eYqIOPe6YxiGoqOjVa9ePS+mCz3sUAIAgJAzbtw4NW7cWHfeeadH6zAyqGLYoQQAACHl559/1ptvvqlZs2YpMjLSo7WcTif3T1YAO5QAACCkpKenq2HDhrr77rs9XouRQRXDDiUAAAgZhmFo0aJFmjJliqpUqeLRWiUlJcrOzmaHsgLYoQQAACFj/Pjxio+P13333efxWjt37pTb7aZQVgCFEgAAhITMzEy9+uqrGjlypKpVq+bxeowMqjgKJQAACAkTJkxQ7dq1NXDgQK+sZxiGqlWrpvr163tlvVBGoQQAAEHvl19+0UsvvaRHHnlEMTExXlnTMAw1a9bsnN8DPJzwFQIAAEFv4sSJiomJ0UMPPeS1NRkZVHEUSgAAENT27dunOXPmaNiwYapZs6bX1mVkUMVRKAEAQFCbPHmyoqKiNHToUK+tWVpaqszMTHYoK4hCCQAAgtaBAwc0c+ZMDRkyRLVr1/baupmZmYwMqgQKJQAACFpTpkyRzWbTsGHDvLouI4Mqh0IJAACCUn5+vmbMmKEHH3xQ8fHxXl3bMAxVqVJFDRs29Oq6oYpCCQAAgtK0adPkcrn06KOPen1tRgZVDl8lAAAQdA4fPqznnntODzzwgM477zyvr8/IoMqhUAIAgKAzY8YMHTlyRCNHjvTJ+owMqhwKJQAACCqFhYV69tln1b9/fzVo0MDr65eVlTEyqJIolAAAIKjMmjVLhw8f1mOPPeaT9bOysuRyuSiUlUChBAAAQaO4uFgZGRnq16+fkpKSfHINRgZVHoUSAAAEjblz5yovL09jxozx2TUMw1BUVJQaNWrks2uEGgolAAAICkePHtXEiRPVp08fNW3a1GfXMQxDTZs2lcPh8Nk1Qg2FEgAABIX58+dr7969Gjt2rE+vw8igyqNQAgCAgFdaWqpnnnlGvXr1UqtWrXx6LUYGVV6E1QEAAADOZsGCBcrOztYHH3zg0+u4XC7t3LmTHcpKYocSAAAENJfLpfT0dN18881q27atT6+VnZ2tsrIyCmUlsUMJAAAC2qJFi7Rjxw4tWbLE59diZNC5YYcSAAAErPLyco0bN0433nij/vSnP/n8eoZhKDIyUomJiT6/VihhhxIAAASst956S9u2bdNrr73ml+sZhqEmTZooIoKKVBk20zRNq0MAAAD8kdvt1oUXXqhGjRrpo48+8ss1b7zxRrndbq1YscIv1wsVvOQNAAAC0rvvvqstW7boiSee8Ns1GRl0biiUAAAg4JimqbS0NF1zzTW68sor/XLN8vJy7dixgxPe54AbBAAAQMBZsWKFNmzYoFWrVvntmrt27VJpaSmF8hywQwkAAAKKaZp6+umn9ec//1lXXXWV367LyKBzxw4lAAAIKCtXrtT69ev18ccfy2az+e26hmEoIiJCjRs39ts1QwU7lAAAIGCYpqnU1FRddtlluu666/x6bcMwlJyczMigc8BXDAAABIwvvvhCX3/9tZYvX+7X3UlJcjqd3D95jtihBAAAASM1NVUXX3yxunfv7vdrMzLo3FEoAQBAQPj666+1atUqPf74437fnXS73dq+fTs7lOeIQgkAAAJCamqqLrjgAv3tb3/z+7V3796tkpISCuU54h5KAABguXXr1unjjz/W4sWLZbf7f7+LkUGeYYcSAABYLjU1Va1atdItt9xiyfUNw5DD4WBk0DlihxIAAFhqw4YNev/99/Xqq6/K4XBYksEwDDVu3FhRUVGWXD/YsUMJAAAslZaWpmbNmumOO+6wLAMjgzxDoQQAAJbZvHmz3nnnHY0ZM8bSgeKMDPIMhRIAAFhm3LhxSkpK0p133mlZBkYGeY57KAEAgCV+/vlnvfHGG3r++ectvXdxz549OnLkCIXSA+xQAgAAS6Snp6tBgwa69957Lc3ByCDPsUMJAAD8bvv27Vq0aJGeffZZValSxdIshmHIbrcrOTnZ0hzBjB1KAADgd+PHj1d8fLwGDBhgdRQZhqGkpCTLi20wo1ACAAC/ysrK0iuvvKIRI0aoWrVqVsdhZJAXUCgBAIBfTZgwQbVq1dLAgQOtjiKJkUHeQKEEAAB+88svv2jevHl65JFHVL16davjyDRNGYbBDqWHKJQAAMBvJk2apOjoaA0ePNjqKJKkvXv3qri4mELpIQolAADwi3379mn27NkaNmyYatasaXUcSYwM8hYKJQAA8IvJkycrMjJSQ4cOtTrK7wzDkM1mU5MmTayOEtQolAAAwOdyc3M1a9YsDRkyRHXq1LE6zu8Mw1BiYqKqVq1qdZSgRqEEAAA+N2XKFEnS8OHDLU5yIkYGeQeFEgAA+NR///tfTZ8+XYMGDVJ8fLzVcU7AyCDvoFACAACfmjZtmsrKyvToo49aHeUEjAzyHgolAADwmcOHD2vq1Km6//77Va9ePavjnGD//v0qLCykUHoBhRIAAPjM888/r+LiYo0aNcrqKCdhZJD3UCgBAIBPFBYWavLkyerfv78aNmxodZyTHCuUTZs2tThJ8KNQAgAAn3jhhRd06NAhPfbYY1ZHOSXDMNSoUSNVq1bN6ihBj0IJAAC87siRI8rIyFC/fv3UuHFjq+OcEiODvIdCCQAAvG7u3LnKzc3VmDFjrI5yWowM8h4KJQAA8KqSkhJNnDhRvXv3VrNmzayOc0qMDPIuCiUAAPCq+fPna8+ePRo7dqzVUU7rwIEDOnz4MIXSSyiUAADAa0pLSzV+/HjddtttOv/8862Oc1qMDPKuCKsDAACA0LFgwQJlZ2fr/ffftzrKGTEyyLvYoQQAAF7hcrmUnp6um266SSkpKVbHOSPDMNSgQQPFxMRYHSUksEMJAAC84vXXX9eOHTv09ttvWx3lrBgZ5F3sUAIAAI+Vl5dr3LhxuuGGG3TxxRdbHeesGBnkXRRKAADgsbfffltbt27VE088YXWUszJNkx1KL6NQAgAAj7jdbqWlpalbt2667LLLrI5zVnl5eTp06BCF0ou4hxIAAHjkvffe0+bNmzVr1iyro1QII4O8jx1KAABwzkzTVGpqqq6++mr9+c9/tjpOhRwrlIH6Lj7BiB1KAABwzlasWKENGzbo888/tzpKhRmGoXr16ql69epWRwkZNtM0TatDAACA4GOapjp27KjIyEitWbNGNpvN6kgV0qdPH2VnZ2vNmjVWRwkZ7FACAIBz8sknn2jdunX66KOPgqZMSr/uULZt29bqGCGFeygBAEClHbt3sn379urWrZvVcSrFMAxOeHsZO5QAAKDSVq9era+++krLli0Lqt3J/Px85efnUyi9jB1KAABQaampqfrTn/6kG264weoolcLIIN9ghxIAAFTK119/rc8//1xvv/12UO1OSowM8hV2KAEAQKWkpqaqbdu26tmzp9VRKs0wDCUkJKhmzZpWRwkp7FACAIAKW7dunT7++GO9/vrrstuDb1+K9/D2jeD7kwAAACyTlpamVq1a6dZbb7U6yjkxDIP7J32AQgkAACpk48aNWr58ucaOHSuHw2F1nHPCyCDfoFACAIAKSUtLU9OmTdW7d2+ro5yTgwcPKjc3l0LpA9xDCQAAzmrLli1asmSJ5s6dq4iI4KwPjAzyHXYoAQDAWY0bN05JSUm66667rI5yzhgZ5DvB+VcMAADgN1u3btUbb7yh6dOnKyoqyuo458wwDMXHx6t27dpWRwk57FACAIAzSk9PV7169XTvvfdaHcUjjAzyHXYoAQDAae3YsUMLFy7U5MmTVbVqVavjeISRQb7DDiUAADit8ePHKy4uTgMGDLA6iscYGeQ7FEoAAHBK2dnZeuWVVzRixAhFR0dbHccjhw8fVk5ODoXSRyiUAADglCZMmKCaNWtq0KBBVkfxGCODfItCCQAATrJnzx7NmzdPw4cPV/Xq1a2O47FjhZIdSt+gUAIAgJNMmjRJ1apV0+DBg62O4hWGYSg2NlZ16tSxOkpIolACAIAT7N+/Xy+88IKGDh2qWrVqWR3HKxgZ5FsUSgAAcILJkycrMjJSDz/8sNVRvIaRQb5FoQQAAL/Lzc3VzJkzNXjwYMXGxlodx2sYGeRbFEoAAPC7qVOnyjRNDR8+3OooXlNYWKh9+/ZRKH2IQgkAACRJBw8e1PTp0zVo0CDVrVvX6jhew8gg36NQAgAASdK0adNUWlqqESNGWB3FqxgZ5HsUSgAAoMOHD2vq1KkaMGCA6tWrZ3UcrzIMQ7Vr1w6pe0IDDYUSAABo5syZKioq0qhRo6yO4nXHRgbZbDaro4QsCiUAAGGuqKhIkydP1j333KNGjRpZHcfrGBnkexRKAADC3AsvvKCDBw9q9OjRVkfxCUYG+R6FEgCAMHbkyBFNmjRJd911l5KTk62O43VFRUXas2cPhdLHKJQAAISxF198UQcOHNCYMWOsjuIT27dvl8TIIF+jUAIAEKZKSko0YcIE9e7dO2R38BgZ5B8USgAAwtTLL7+sPXv26O9//7vVUXzGMAzVrFlT8fHxVkcJaRRKAADCUFlZmcaPH69bb71V559/vtVxfIaRQf4RYXUAAADgfwsWLFBWVpaWL19udRSfYmSQf7BDCQBAmHG5XEpPT1fPnj2VkpJidRyfYmSQf7BDCQBAmFm8eLG2b9+uN9980+ooPnXkyBHt3r2bQukH7FACABBGysvLNW7cOHXv3l2XXHKJ1XF8ipFB/sMOJQAAYWTJkiX6+eef9fLLL1sdxecYGeQ/7FACABAm3G630tLSdN1116lDhw5Wx/E5wzBUvXp1JSQkWB0l5LFDCQBAmFi2bJk2bdqk559/3uoofsHIIP+xmaZpWh0CAAD4lmmaateunWrUqKEvvvjC6jh+0bVrV8XFxYX84aNAwA4lAABh4IMPPtAPP/ygTz/91OoofmMYRli8tB8IuIcSAIAQZ5qmUlNTdcUVV+iaa66xOo5fHD16VLt27eJAjp+wQwkAQIj79NNPtXbtWn344Ydhcz/hjh07ZJomI4P8hB1KAABCXGpqqtq1a6frr7/e6ih+w8gg/2KHEgCAELZ69WqtWbNG7733XtjsTkq/Fsro6GjVq1fP6ihhgR1KAABCWGpqqi666CLdeOONVkfxK0YG+Rc7lAAAhKhvvvlGn332md56662wK1aGYXD/pB+xQwkAQIhKTU1VmzZtdNNNN1kdxe8Mw+D+ST9ihxIAgBC0fv16ffTRR1q0aJHs9vDaPyopKVF2djaF0o/C608YAABhIi0tTS1bttRtt91mdRS/27lzp9xuN4XSj9ihBAAgxPz4449atmyZXn75ZTkcDqvj+N2xkUHcQ+k/7FACABBi0tLS1KRJE/Xu3dvqKJYwDEPVqlVT/fr1rY4SNtihBAAghPznP//RkiVLNHv2bEVGRlodxxJOp1PNmjULu3tHrcRXGgCAEDJu3Dg1atRI/fr1szqKZRgZ5H8USgAAQsS2bdu0ePFiPfbYY4qKirI6jmUYGeR/FEoAAEJEenq6zjvvPPXv39/qKJYpLS1VZmYmhdLPuIcSAIAQsGPHDr322mvKyMhQ1apVrY5jmczMTEYGWYAdSgAAQsAzzzyjuLg43X///VZHsRQjg6xBoQQAIMhlZ2fr5Zdf1qOPPqro6Gir41jKMAxVqVJFDRs2tDpKWKFQAgAQ5CZOnKgaNWpo0KBBVkexHCODrMFXGwCAILZ37169+OKLGj58uGrUqGF1HMsxMsgaFEoAAILYpEmTVLVqVQ0ZMsTqKAGBkUHWoFACABCkcnJy9MILL2jo0KGqVauW1XEsV1ZWxsggi1AoAQAIUpMnT5bD4dCwYcOsjhIQsrKy5HK5KJQWoFACABCE8vLy9Pzzz2vw4MGKjY21Ok5AYGSQdSiUAAAEoalTp8o0TT3yyCNWRwkYhmEoKipKjRo1sjpK2KFQAgAQZA4ePKhp06Zp4MCBqlu3rtVxAobT6VTTpk3lcDisjhJ2KJQAAASZ6dOnq6SkRCNGjLA6SkBhZJB1KJQAAASRgoICTZ06VQMGDFD9+vWtjhNQGBlkHQolAABBZObMmSooKNCoUaOsjhJQXC6Xdu7cSaG0CIUSAIAgUVRUpIyMDN1zzz1KTEy0Ok5Ayc7OVllZGYXSIhRKAACCxOzZs3Xw4EGNGTPG6igBh5FB1qJQAgAQBI4cOaJJkybpzjvvVHJystVxAo5hGIqMjGTn1iIUSgAAgsC8efOUk5OjsWPHWh0lIDmdTjVp0kQRERFWRwlLFEoAAAJcSUmJJkyYoDvuuIN7BE+DkUHWolACABDgXnnlFf3yyy/6+9//bnWUgMXIIGtRKAEACGBlZWUaP368brnlFrVu3drqOAGpvLxcO3bsoFBaiBsNAAAIYK+99poyMzP13nvvWR0lYO3atUulpaUUSguxQwkAQIByuVxKT0/X3/72N1144YVWxwlYjAyyHjuUAAAEqDfeeEOGYWjx4sVWRwlohmEoIiJCjRs3tjpK2GKHEgCAAOR2uzVu3Dj99a9/1aWXXmp1nIDmdDqVnJzMyCAL8ZUHACAALVmyRD/99JNeeuklq6MEPEYGWY8dSgAAAozb7VZaWpquvfZadezY0eo4AY+RQdajUAIAEGCWL1+uf//733riiSesjhLw3G63tm/fTqG0GIUSAIAAYpqmUlNT1blzZ3Xu3NnqOAFv9+7dKikpoVBajHsoAQCw2A8//KAvv/xS99xzj77++mt9//33+uSTT6yOFRQYGRQY2KEEAMBiL774ooYPH65GjRrp/vvvV7t27dS1a1erYwUFwzDkcDgYGWQxCiUAABaz2+1yOBwqLCzUL7/8ok2bNmns2LHKzc21OlrAczqdaty4saKioqyOEtYolAAAWMxut8tu/9+P5JKSEj3zzDMaMmSIhamCAyODAgOFEgAAi9ntdpmmecK/t2rVSv/85z+tCxUkGBkUGCiUAABYzG63q7y8/Pd/v+OOO/T999+rVatWFqYKfIwMChwUSgAALLZ//36ZpimHw6E5c+ZowYIFiomJsTpWwNuzZ4+OHDlCoQwAjA0CAMAPikpcyswrUqnLragIu5LjYhRT5dcfwzExMYqOjtbq1avVrl07i5MGD0YGBQ4KJQAAPuLcX6CFa7O1amuOsvOLZR73mE1SUmy0urRK0MjUyZo9e7ZsNptVUYOSYRiy2+1KTk62OkrYo1ACAOBlu/KLNXbpJq0xcuWw21TuNk96jikpK79YC9Zm6eVvM9WpebzSe6YoMTba/4GDlNPpVFJSkqpUqWJ1lLDHPZQAAHjR4vXZunbKan2zI0+STlkmj3fs8W925OnaKau1eH22zzOGCkYGBQ4KJQAAXjJjlVOj39mkEpf7rEXyj8rdpkpcbo1+Z5NmrHL6KGFoYWRQ4KBQAgDgBYvXZytj5TavrJWxcpveYKfyjEzTpFAGEAolAAAe2pVfrCeXbfHqmv9YtkW78ou9umYo2bt3r4qLiymUAYJCCQCAh8Yu3SRXJV/iPhuX29TYpZu8umYoYWRQYKFQAgDgAef+Aq0xcit9z+TZlLtNrTFyZeQUeHXdUGEYhmw2m5o0aWJ1FIhCCQCARxauzZbD7pv5kQ67Ta99x72Up+J0OpWYmKiqVataHQWiUAIA4JFVW3O8vjt5TLnb1KptOT5ZO9gxMiiwUCgBADhHhSUuZfv44Ex2XrGKSlw+vUYw4oR3YKFQAgBQSaWlpdq7d68+W/ujfLM3+T+mpMy8Ih9fJbgwMijw8NaLAICwZpqmDh48qNzcXOXm5urAgQNn/fWhQ4ckSVH1W6p+v2d9nrHU5fb5NYLJ/v37VVhYSKEMIBRKAEBIOXr0aIVK4fG/Li8vP2md2rVrKz4+XnXr1lV8fLzatGnz+6+P/X5hZG2N/uKQzz+nqAheUDweI4MCD4USgN8UlbiUmVekUpdbURF2JcfFKKYK34ZweuXl5frvf/9boWJ47J9FRSe/PFylSpUTymD9+vWVkpJyQmE8/tdxcXGKjIw8a76iEpfGfPGxT1/2tklKjovx4RWCz7FC2bRpU4uT4Bi+kwPwKef+Ai1cm61VW3OUnV98wg9em6Sk2Gh1aZWgPh2S1OK8GlbFhB+YpqmioqJK7Rzm5+fL7T7x5V6bzabY2NgTiuDFF198Uik8/tcxMTGy2bw/2iemSoSSYqOV5cODOUlx0fzF6w+cTqcaNWqkatWqWR0Fv+FPKACf2JVfrLFLN2mNkSuH3XbKsSqmpKz8Yi1Ym6WXv81Up+bxSu+ZosTYaP8HRqWVlZUpPz//pB3CM/366NGjJ60TExNzQgFMTk5W+/btT1sQ69SpI4fDYcFnfGpdWiVowdosn4wOctht6tIywevrBjtGBgUeCiUAr1u8PltPLtvy+1vRne0H7bHHv9mRp2unrNZTPdqqV/skn+fE/5imqcOHD1e4GB44cEAHDx48aR2Hw/F7+TtWAJs1a3bancP4+Pig32Xq0yFJL3+b6ZO1y92m+nbk/4U/MgxDl156qdUxcBwKJQCvmrHKqYyV287pY8vdpsrdpka/s0m5hSUa3IUdiHNVUlJSqZeWc3NzVVZWdtI6NWvWPKH8tWrVSldeeeVpC2KtWrVkt4fXAZIW59VQp+bx+mZHnld3KR12m65oGqfmCdwKcrxjI4Nuv/12q6PgOBRKAF6zeH32OZfJP8pYuU11q1fR7exUyu126+DBg2c8iPLHXxcUnPz+z5GRkb8Xv7p16yohIeGUJ5eP32GMioqy4DMOPuk9U3TtlNVeLZQRdpvSe6Z4bb1QceDAAR0+fJiRQQGGQgnAK3blF+vJZVu8uuY/lm3RFc3iQ+6eyuLi4kq9tJyXl3fSwRRJio2NPaEIXnjhhWd8ablGjRo+OZgCKTE2Wk/1aKvR72zy2ppP92gbcn/2vYGRQYGJQgnAK8Yu3fT7PZPe4nKbGrt0kxb073DKxw8dOqRatWp59ZqV5XK5lJ+fX6mCeOTIkZPWqVat2gnlLzEx8feTy6cqiLGxsYqI4Ft4IOnVPkm5hSVe2aUf2a0Vu/OnwcigwMR3IwAec+4v0Boj1+vrlrtNrTFyZeQUnHAf2c6dOzV06FB9+OGHMgxDycnJXrmeaZoqKCio1L2H//3vf2WaJxZpu92uuLi4EwpgcnLyKYvhsX9GR7MTFQoGd2mh+OpVfj+UVpmXwB12myLsNj3doy1l8gycTqcaNGigmBhmcwYSCiUAjy1cm33a0UCecthteu27bP2zR1sdPXpUkyZNUlpamlwul9xutzIzM09bKEtLS5WXl1epew9LS0tPWqdGjRonFMHmzZurY8eOp31puU6dOmF3MAX/06t9kq5sFn/WsVnHHHv8iqZxjM2qAEYGBSab+ce/WgNAJV01aZVPBzs3jovWY22OaNCgQdq1a9cJO4K9e/dWgwYNTlkSDx8+fNJaERERpy2Cp3vHlKpVq/rsc0No+32w/7YcZeedYrB/XLS6tExQ345JnOauoPbt2+uiiy7Siy++aHUUHIdCCcAjhSUupfzTt289J9NU9rO3yiw7eSh2tWrV1KhRowoXxJo1a3IwBZbgrUc9Z5qm6tSpo9GjR2v06NFWx8Fx+JMMwCNZeUW+LZOSZLPpkquu149frFB5efnvO5QREREaM2aMnnjiCV8nADwWUyVCbRtYe4gs2OXl5enQoUOMDApA3OQDwCOlrpPH2fjC3HnzlZOToylTpvz+w8Tlcik31/uHgQAEJkYGBS4KJQCPREX459tIVIRdderU0cMPP6xt27Zp9erV6tevn7p27eqX6wOw3rFC2axZM4uT4I94yRuAR5LjYmSTfPqyt+236/z+7zabOnfurM6dO/vwqgACjdPpVL169VS9enWro+AP2KEE4JGYKhFK8vGYk6S4aA4vAGBkUACjUALwyN69e1W9IEt2Hx2cdtht6tIywTeLAwgqhmFwICdAUSgBnJNdu3ZpyJAhatKkib55daJ8MNNc0q/vltO3I+8aAoBCGcgolAAqZceOHbr//vvVrFkzLVq0SI8//rh2bvxGnZrHy+HlbUqH3aZOzeMZ+AxA+fn5ys/Pp1AGKAolgAr5+eef1a9fP7Vs2VLvvfeexo0bp6ysLD3++OOqXbu20numKMLLhTLCblN6zxSvrgkgODEyKLBRKAGc0aZNm9SrVy+1adNGn332mZ599lnt3LlTI0eOPOGkZWJstJ7q0dar1366R1ve1xiAJEYGBToKJYBT+v7779WzZ09deOGF+u677zRr1ixt375dQ4cOVXT0qUter/ZJGtGtpVeuP7JbK93ennsnAfzK6XQqISFBNWvWtDoKToFCCeAE3377rf7617+qXbt22rx5s1566SU5nU498MADqlKlylk/fnCXFnrmphRVibBX+p5Kh92mKhF2TbgpRQ914T4pAP/DyKDARqEEINM09cUXX6hr16664oorlJWVpYULF+qnn37SPffco8jIyEqt16t9kj4dfpWuaBonSWctlscev6JpnD4dfhU7kwBOwgnvwMakYCCMmaaplStXKi0tTV999ZX+9Kc/6e2331bPnj1lt3v2983E2Ggt6N9Bzv0FWrg2W6u25Sg7r/iEd9Sx6deh5V1aJqhvxyROcwM4LcMw1L17d6tj4DQolEAYMk1Ty5cvV1pamtavX6/LLrtMy5cvV/fu3WWzefekdovzauifPdrqn2qrohKXMvOKVOpyKyrCruS4GN4BB8BZHTx4ULm5uexQBjC+kwNhxO12a8mSJRo3bpx+/PFHderUSStXrtS1117r9SJ5KjFVItS2QS2fXwdAaGFkUODjHkogDLhcLi1cuFAXXHCBbrvtNtWtW1erV6/Wl19+qeuuu84vZRIAzhUjgwIfhRIIYaWlpXrppZfUunVr9e3bV02bNtW3336rTz75RJ07d7Y6HgBUiNPpVHx8vGrXrm11FJwGL3kDIejo0aOaP3++nnnmGWVnZ+umm27Sm2++qYsvvtjqaABQaYwMCnwUSiCEFBcXa86cOZo0aZL27dun22+/XStWrNAFF1xgdTQAOGeMDAp8vOQNhICCggJNmDBBycnJGjFihLp166affvpJixYtokwCCHoUysDHDiUQxA4ePKhp06Zp6tSpKiws1D333KPRo0erSZMmVkcDAK84fPiwcnJyKJQBjkIJBKHc3FxNmTJFM2bMUGlpqQYMGKBRo0apUaNGVkcDAK9iZFBwoFACQWTfvn3KyMjQrFmzZLPZNGjQID366KOqV6+e1dEAwCeOFUp2KAMbhRIIArt27dKkSZM0d+5cRUVFafjw4Ro2bJji4+OtjgYAPuV0OhUbG6s6depYHQVnQKEEAtjOnTv1zDPPaP78+apevbrGjh2rIUOGMIsNQNhgZFBwoFACAWjr1q0aP368XnvtNcXFxSktLU2DBg1SjRo1rI4GAH7FCe/gwNggIIBs3rxZd9xxh1q3bq1PPvlEkydP1s6dOzVq1CjKJICwRKEMDhRKIAD88MMPuummm5SSkqJvv/1WM2fO1Pbt2/Xwww8rOjra6ngAYImCggLt27ePQhkEKJSAhb777jt1795dl156qf79739r3rx5cjqdGjhwoKpWrWp1PACw1Pbt2yUxMigYUCgBC6xevVrXXnutLr/8cu3cuVOvvfaafv75Z917772KjIy0Oh4ABARGBgUPCiXgJ6ZpauXKlercubOuvvpq5ebm6q233tLmzZvVp08fRURwRg4Ajud0OlW7dm3FxsZaHQVnQaEEfMw0TS1fvlwdO3bU9ddfr6NHj2rZsmXasGGDbrnlFtnt/G8IAKdybGSQzWazOgrOgp9kgI+43W69/fbbuvjii9WjRw9FRUXp448/1tq1a3XjjTfyDRIAzoIT3sGDQgl4mcvl0qJFi5SSkqJbb71V8fHxWrVqlb788kt169aNIgkAFUShDB4USsBLysrKNH/+fLVu3Vp9+vRRcnKyvvnmG3366ae6+uqrKZIAUAlFRUXas2cPhTJIUCgBD5WUlOiFF15QixYtdO+99+qCCy7Qv/71L61YsUKXX3651fEAICgxMii4cKwUOEfFxcWaO3euJk6cqL179+r222/X8uXLlZKSYnU0AAh6jAwKLhRKoJIKCgo0a9YsTZ48WXl5eerbt6/GjBmjVq1aWR0NAEKG0+lUzZo1FR8fb3UUVACFEqiggwcPavr06Zo6daoKCgp09913a/To0WratKnV0QAg5DAyKLhQKIGzyM3N1dSpUzV9+nSVlJRowIABGjVqlBITE62OBgAhixPewYVCCZzGvn37NHnyZM2aNUumaWrQoEF69NFHVb9+faujAUDIMwxDV155pdUxUEEUSuAPdu/erUmTJmnOnDmKjIzUww8/rGHDhqlu3bpWRwOAsFBcXKzdu3ezQxlEKJTAb3bu3KkJEyZo/vz5iomJ0ZgxYzRkyBDVqVPH6mgAEFZ27NghiZFBwYRCibC3bds2jR8/XgsWLFCdOnX01FNP6cEHH1TNmjWtjgYAYYmRQcGHQomwtXnzZqWnp+uNN97Qeeedp0mTJun+++9XTEyM1dEAIKw5nU5Vr15dCQkJVkdBBVEoEXY2bNigtLQ0vfPOO0pMTNT06dN17733qmrVqlZHAwCIkUHBiLdeRNhYu3atbrjhBl1yySXauHGjXnzxRRmGoQcffJAyCQABhJFBwYdCiZD35Zdf6rrrrlPHjh21fft2LViwQFu3blX//v0VFRVldTwAwB9QKIMPhRIhyTRNffLJJ+rcubOuuuoq5eTk6M0339TmzZvVt29fRURwtwcABKKjR49q165dFMogQ6FESDFNU++//74uv/xydevWTUeOHNF7772nDRs26NZbb5XD4bA6IgDgDHbs2CHTNBkZFGQolAgJbrdbS5Ys0SWXXKIbb7xRERER+uijj7Ru3Tr16NFDdjt/1AEgGDAyKDjxUxZBrby8XIsWLVJKSopuueUWxcbG6vPPP9eaNWt0/fXXc0IQAIKM0+lUTEyM6tWrZ3UUVAKFEkGprKxML7/8slq3bq0+ffqocePG+vrrr/XZZ5+pS5cuFEkACFLHDuTwfTy4UCgRVEpKSjR79my1bNlS99xzj9q0aaP169frgw8+0BVXXGF1PACAhzjhHZwolAgKxcXFmjZtmpo1a6ZBgwbpsssu048//qh3331X7dq1szoeAMBLKJTBidkpCGiFhYWaNWuWMjIylJeXp969e2vs2LE6//zzrY4GAPCykpISZWdnUyiDEIUSAenQoUOaPn26pkyZooKCAvXr10+jR49Ws2bNrI4GAPCRnTt3yu12MzIoCFEoEVDy8vI0depUTZ8+XUePHtV9992nUaNGKSkpyepoAAAfY2RQ8KJQIiDs379fkydP1syZM2WapgYOHKgRI0aofv36VkcDAPiJ0+lUtWrV+N4fhCiUsNQvv/yiSZMmac6cOYqIiNDQoUM1fPhw1a1b1+poAAA/O3YghzejCD4USlgiMzNTEyZM0EsvvaTo6Gg99thjGjJkiGJjY62OBgCwCCe8gxd/BYBfOZ1O3XvvvWrRooXefvttPfXUU8rKytKTTz5JmQSAMEehDF7sUMIvtmzZovT0dC1evFgJCQmaMGGCHnjgAcXExFgdDQAQAEpLS5WZmUmhDFIUSvjUhg0bNG7cOC1ZskSJiYmaNm2a+vfvr6pVq1odDQAQQDIzMxkZFMR4yRs+sW7dOt1444265JJLtGHDBs2dO1eGYeihhx6iTAIATsLIoOBGoYRXrVmzRt26dVOHDh3kdDr16quvauvWrbrvvvsUFRVldTwAQIByOp2qWrWqGjZsaHUUnAMKJTxmmqY+/fRTXXXVVercubP27dunN954Q1u2bNGdd96piAjurAAAnJlhGGrWrBkjg4IU/9VwzkzT1IoVK3TFFVfouuuuU1FRkd59911t3LhRt912mxwOh9URAQBBghPewY1CiUpzu9165513dOmll+qGG26Q3W7Xhx9+qPXr1+v//b//x98uAQCVRqEMbvzkR4WVl5dr8eLFuuiii3TzzTerdu3a+uyzz/TVV1/p//7v/2Sz2ayOCAAIQmVlZdq5cyeFMohRKHFWZWVleuWVV9SmTRvdcccdatSokb766it9/vnnuuaaayiSAACPZGVlqby8nJFBQYxCidMqKSnR7Nmz1bJlS919991q3bq11q1bpw8//FBXXnml1fEAACGCkUHBj+O3OMmRI0f04osvauLEifrll19066236t1339VFF11kdTQAQAhyOp2KiopSo0aNrI6Cc0ShxO8KCwv1wgsvKCMjQ7m5uerdu7fGjBmj1q1bWx0NABDCjo0MYjpI8KJQQocOHdKMGTM0ZcoUHTp0SP369dOYMWPUrFkzq6MBAMIAJ7yDH4UyjOXn52vq1KmaNm2ajh49qv79++uxxx5TUlKS1dEAAGHEMAx1797d6hjwAIUyDOXk5Gjy5MmaOXOmysvLNXDgQI0YMUINGjSwOhoAIMy4XC7t2LGDHcogR6EMI7/88osyMjI0e/ZsORwODR48WMOHD1dCQoLV0QAAYSo7O1sul4uRQUGOQhkGsrKyNGHCBM2bN0/R0dEaNWqUhg4dqtjYWKujAQDCHCODQgOFMoQZhqHx48fr1VdfVe3atfXPf/5TDz74oGrVqmV1NAAAJP06MigyMlKJiYlWR4EHKJQh6D//+Y/S09P1+uuvKyEhQRMmTNADDzygmJgYq6MBAHACwzDUtGlTRURQSYIZ//VCyMaNGzVu3DgtWbJEjRo10rRp03TvvfeqWrVqVkcDAOCUGBkUGnjrxRCwbt069ejRQxdffLG+//57zZ49W4Zh6KGHHqJMAgACGoUyNFAog9hXX32l66+/Xh06dNC2bdv0yiuvaNu2bRowYICioqKsjgcAwBmVl5czMihEUCiDjGma+uyzz3T11VerU6dO2rNnjxYvXqwtW7borrvu4h4UAEDQ2LVrl0pLSxkZFAIolEHCNE198MEHuvLKK3XttdeqoKBAS5cu1Y8//qjbb7+d9z8FAAQdRgaFDgplgHO73Vq6dKnatWv3+9tSffDBB/rXv/6lv/3tb7Lb+U8IAAhOTqdTERERaty4sdVR4CHaSIAqLy/XG2+8oYsuukg33XSTatasqc8++0xff/21/vKXv8hms1kdEQAAjxiGoSZNmnC7VgigUAaYsrIyvfrqq2rbtq169eqlhg0bas2aNVq1apWuueYaiiQAIGRwwjt0UCgDRElJiebMmaNWrVqpX79+atWqldatW6ePPvpIf/7zn62OBwCA11EoQweF0mJHjhzRjBkz1Lx5cw0cOFDt2rXTxo0b9d5776l9+/ZWxwMAwCfcbre2b99OoQwR3LRgkcLCQs2ePVsZGRnKyclR7969NWbMGLVp08bqaAAA+Nzu3btVUlLCyKAQQaH0s8OHD2vGjBl69tlndejQId11110aM2YMf0MDAIQVRgaFFgqln+Tn5+u5557TtGnTVFxcrP79++uxxx5jVAIAICw5nU45HA4lJydbHQVeEPaFsqjEpcy8IpW63IqKsCs5LkYxVbz3ZcnJydGzzz6r559/XuXl5XrggQc0cuRINWjQwGvXAAAg2BiGoeTkZEVGRlodBV4QloXSub9AC9dma9XWHGXnF8s87jGbpKTYaHVplaA+HZLU4rwaZ1wrPz9fGRkZGjlypOrUqfP77+/Zs0cZGRl64YUX5HA49NBDD+mRRx5RQkKCbz4pAACCCCe8Q0tYFcpd+cUau3ST1hi5cthtKnebJz3HlJSVX6wFa7P08reZ6tQ8Xuk9U5QYG33Sc91ut/r27asPP/xQkpSenq6srCxNnDhR8+bNU9WqVTVy5Eg9/PDDio2N9fWnBwBA0DAMQ1dddZXVMeAlNtM0T25VIWjx+mw9uWyLXG7zlEXydBx2myLsNj3Vo616tU864bHx48dr7NixkqRq1arp5ptv1uLFi1WrVi098sgjeuihh1SrVi2vfh4AAAQ7t9utmJgYjR8/XsOGDbM6DrwgLArljFVOZazc5vE6I7q11OAuv443WLVqlbp27arjv3wxMTF66qmn9MADD6h69eoeXw8AgFC0e/duJSYm6v3331f37t2tjgMvCPmXvBevz/ZKmZSkjJXbVLd6FXVqGKGePXvqj13cZrNpwIABlEkAAM6AkUGhJ6TfKWdXfrGeXLbFq2v+Y9kWdezaXYcOHTrpscLCQs2ZM8er1wMAINQ4nU7Z7XY1adLE6ijwkpDeoRy7dJNclbhfsiJcblM1r31A7arPU8OGDSVJ5eXlcrlccrlcTPwHAOAsDMNQ48aNFRUVZXUUeEnIFkrn/gKtMXK9vm6521Rh9US9u+JzNU8480ghAABwMkYGhZ6Qfcl74dpsOew2n6ztsNv02nfZPlkbAIBQR6EMPSFbKFdtzanUeKDKKHebWrUtxydrAwAQykzTpFCGoJAslIUlLmXnF/v0Gtl5xSoqcfn0GgAAhJq9e/equLiYMwchJiQLZVZekXw9XNOUlJlX5OOrAAAQWhgZFJpCslCWutwhdR0AAEKF0+mUzWZjZFCICclCGRXhn0/LX9cBACBUGIahpKQkVa1a1eoo8KKQbETJcTHyzfnu/7H9dh0AAFBxHMgJTSFZKGOqRCgpNtqn10iKi1ZMlZAd4wkAgE9QKENTSBZKSerSKsGncyi7tEzwydoAAIQq0zTldDoplCEoZAtlnw5JPp1D2bdjkk/WBgAgVO3fv19FRUWMDApBIVsoW5xXQ52ax3t9l9Jht6lT83jedhEAgEpiZFDoCtlCKUnpPVMU4eVCGWG3Kb1nilfXBAAgHDidTklS06ZNLU4CbwvpQpkYG62nerT16ppP92irRB8f+AEAIBQZhqHExERVq1bN6ijwspAulJLUq32SRnRr6ZW1RnZrpdvbc+8kAADnghPeoSvkC6UkDe7SQs/clKIqEfZK31PpsNtUJcKuCTel6KEu/E8AAMC5olCGrrAolNKvO5WfDr9KVzSNk6SzFstjj1/RNE6fDr+KnUkAADzAyKDQFlaTuRNjo7Wgfwc59xdo4dpsrdqWo+y8Yh0/XMimX4eWd2mZoL4dkzjNDQCAFxw4cEAFBQWMDApRNtM0fTOsMUgUlbiUmVekUpdbURF2JcfF8A44AAB42TfffKMrr7xS//73v5WSwrSUUBP2zSmmSoTaNqhldQwAAELasZFBzZo1szgJfCFs7qEEAADWMQxDDRs2VHQ0o/dCEYUSAAD4HCe8QxuFEgAA+ByFMrRRKAEAgE8xMij0USgBAIBP5eXl6dChQ4wMCmEUSgAA4FOGYUgSO5QhjEIJAAB8ipFBoY9CCQAAfMowDNWvX1/Vq1e3Ogp8JOwHmwMAAO87/p3oNmblqmnL1lZHgg+F/VsvAgAA73DuL9DCtdlatTVH2fnFOqFgmKYax8WoS6sE9emQpBbn1bAqJnyAQgkAADyyK79YY5du0hojVw67TeXu01eLY493ah6v9J4pSozlnXNCAYUSAACcs8Xrs/Xksi1yuc0zFsk/cthtirDb9FSPturVPsmHCeEPFEoAAHBOZqxyKmPlNo/XGdGtpQZ3YUZlMOOUNwAAqLTF67O9UiYlKWPlNr2xPtsra8EaFEoAAFApu/KL9eSyLV5d8x/LtmhXfrFX14T/UCgBAECljF26Sa5K3C9ZES63qbFLN3l1TfgPhRIAAFSYc3+B1hi5lTqAUxHlblNrjFwZOQVeXRf+QaEEAAAVtnBtthx2m0/Wdthteu077qUMRhRKAABQYau25nh9d/KYcrepVdtyfLI2fItCCQAAKqSwxKVsHx+cyc4rVlGJy6fXgPdRKAEAQIVk5RXJ18OrTUmZeUU+vgq8jUIJAAAqpNTlDqnrwHsolAAAoEKiIvxTG/x1HXgP/8UAAECFJMfFyDfnu//H9tt1EFwolAAAoEJiqkQoKTbap9dIiotWTJUIn14D3kehBAAAFdalVYJP51B2aZngk7XhWxRKAABQYX06JPl0DmXfjkk+WRu+RaEEAAAV1uK8GurUPN7ru5QOu02dmsereUINr64L/6BQAgCASknvmaIILxfKCLtN6T1TvLom/IdCCQAAKiUxNlpP9Wjr1TWf7tFWiT4+8APfoVACAIBK69U+SSO6tfTKWiO7tdLt7bl3MpjZTNP09bsoAQCAELV4fbaeXLZFLrdZqcM6DrtNEXabnu7RljIZAiiUAADAI7vyizV26SatMXLlsNvOWCyPPd6pebzSe6bwMneIoFACAACvcO4v0MK12Vq1LUfZecU6vmDY9OvQ8i4tE9S3YxKnuUMMhRIAAHhdUYlLmXlFKnW5FRVhV3JcDO+AE8IolAAAAPAIp7wBAADgEQolAAAAPEKhBAAAgEcolAAAAPAIhRIAAAAeoVACAADAIxRKAAAAeIRCCQAAAI9QKAEAAOARCiUAAAA8QqEEAACARyiUAAAA8AiFEgAAAB6hUAIAAMAjFEoAAAB4hEIJAAAAj1AoAQAA4BEKJQAAADxCoQQAAIBHKJQAAADwCIUSAAAAHqFQAgAAwCMUSgAAAHiEQgkAAACPUCgBAADgEQolAAAAPEKhBAAAgEcolAAAAPAIhRIAAAAeoVACAADAIxRKAAAAeIRCCQAAAI9QKAEAAOARCiUAAAA8QqEEAACARyiUAAAA8AiFEgAAAB75/w/zjz6pNbEhAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G = nx.from_numpy_array(A.T,create_using = nx.DiGraph)\n",
    "nx.draw(G)\n",
    "nx.is_directed_acyclic_graph(G)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NO tears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit as sigmoid\n",
    "import igraph as ig\n",
    "import random\n",
    "\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "def is_dag(W):\n",
    "    G = ig.Graph.Weighted_Adjacency(W.tolist())\n",
    "    return G.is_dag()\n",
    "\n",
    "\n",
    "def simulate_dag(d, s0, graph_type):\n",
    "    \"\"\"Simulate random DAG with some expected number of edges.\n",
    "\n",
    "    Args:\n",
    "        d (int): num of nodes\n",
    "        s0 (int): expected num of edges\n",
    "        graph_type (str): ER, SF, BP\n",
    "\n",
    "    Returns:\n",
    "        B (np.ndarray): [d, d] binary adj matrix of DAG\n",
    "    \"\"\"\n",
    "    def _random_permutation(M):\n",
    "        # np.random.permutation permutes first axis only\n",
    "        P = np.random.permutation(np.eye(M.shape[0]))\n",
    "        return P.T @ M @ P\n",
    "\n",
    "    def _random_acyclic_orientation(B_und):\n",
    "        return np.tril(_random_permutation(B_und), k=-1)\n",
    "\n",
    "    def _graph_to_adjmat(G):\n",
    "        return np.array(G.get_adjacency().data)\n",
    "\n",
    "    if graph_type == 'ER':\n",
    "        # Erdos-Renyi\n",
    "        G_und = ig.Graph.Erdos_Renyi(n=d, m=s0)\n",
    "        B_und = _graph_to_adjmat(G_und)\n",
    "        B = _random_acyclic_orientation(B_und)\n",
    "    elif graph_type == 'SF':\n",
    "        # Scale-free, Barabasi-Albert\n",
    "        G = ig.Graph.Barabasi(n=d, m=int(round(s0 / d)), directed=True)\n",
    "        B = _graph_to_adjmat(G)\n",
    "    elif graph_type == 'BP':\n",
    "        # Bipartite, Sec 4.1 of (Gu, Fu, Zhou, 2018)\n",
    "        top = int(0.2 * d)\n",
    "        G = ig.Graph.Random_Bipartite(top, d - top, m=s0, directed=True, neimode=ig.OUT)\n",
    "        B = _graph_to_adjmat(G)\n",
    "    else:\n",
    "        raise ValueError('unknown graph type')\n",
    "    B_perm = _random_permutation(B)\n",
    "    assert ig.Graph.Adjacency(B_perm.tolist()).is_dag()\n",
    "    return B_perm\n",
    "\n",
    "\n",
    "def simulate_parameter(B, w_ranges=((-2.0, -0.5), (0.5, 2.0))):\n",
    "    \"\"\"Simulate SEM parameters for a DAG.\n",
    "\n",
    "    Args:\n",
    "        B (np.ndarray): [d, d] binary adj matrix of DAG\n",
    "        w_ranges (tuple): disjoint weight ranges\n",
    "\n",
    "    Returns:\n",
    "        W (np.ndarray): [d, d] weighted adj matrix of DAG\n",
    "    \"\"\"\n",
    "    W = np.zeros(B.shape)\n",
    "    S = np.random.randint(len(w_ranges), size=B.shape)  # which range\n",
    "    for i, (low, high) in enumerate(w_ranges):\n",
    "        U = np.random.uniform(low=low, high=high, size=B.shape)\n",
    "        W += B * (S == i) * U\n",
    "    return W\n",
    "\n",
    "\n",
    "def simulate_linear_sem(W, n, sem_type, noise_scale=None):\n",
    "    \"\"\"Simulate samples from linear SEM with specified type of noise.\n",
    "\n",
    "    For uniform, noise z ~ uniform(-a, a), where a = noise_scale.\n",
    "\n",
    "    Args:\n",
    "        W (np.ndarray): [d, d] weighted adj matrix of DAG\n",
    "        n (int): num of samples, n=inf mimics population risk\n",
    "        sem_type (str): gauss, exp, gumbel, uniform, logistic, poisson\n",
    "        noise_scale (np.ndarray): scale parameter of additive noise, default all ones\n",
    "\n",
    "    Returns:\n",
    "        X (np.ndarray): [n, d] sample matrix, [d, d] if n=inf\n",
    "    \"\"\"\n",
    "    def _simulate_single_equation(X, w, scale):\n",
    "        \"\"\"X: [n, num of parents], w: [num of parents], x: [n]\"\"\"\n",
    "        if sem_type == 'gauss':\n",
    "            z = np.random.normal(scale=scale, size=n)\n",
    "            x = X @ w + z\n",
    "        elif sem_type == 'exp':\n",
    "            z = np.random.exponential(scale=scale, size=n)\n",
    "            x = X @ w + z\n",
    "        elif sem_type == 'gumbel':\n",
    "            z = np.random.gumbel(scale=scale, size=n)\n",
    "            x = X @ w + z\n",
    "        elif sem_type == 'uniform':\n",
    "            z = np.random.uniform(low=-scale, high=scale, size=n)\n",
    "            x = X @ w + z\n",
    "        elif sem_type == 'logistic':\n",
    "            x = np.random.binomial(1, sigmoid(X @ w)) * 1.0\n",
    "        elif sem_type == 'poisson':\n",
    "            x = np.random.poisson(np.exp(X @ w)) * 1.0\n",
    "        else:\n",
    "            raise ValueError('unknown sem type')\n",
    "        return x\n",
    "\n",
    "    d = W.shape[0]\n",
    "    if noise_scale is None:\n",
    "        scale_vec = np.ones(d)\n",
    "    elif np.isscalar(noise_scale):\n",
    "        scale_vec = noise_scale * np.ones(d)\n",
    "    else:\n",
    "        if len(noise_scale) != d:\n",
    "            raise ValueError('noise scale must be a scalar or has length d')\n",
    "        scale_vec = noise_scale\n",
    "    if not is_dag(W):\n",
    "        raise ValueError('W must be a DAG')\n",
    "    if np.isinf(n):  # population risk for linear gauss SEM\n",
    "        if sem_type == 'gauss':\n",
    "            # make 1/d X'X = true cov\n",
    "            X = np.sqrt(d) * np.diag(scale_vec) @ np.linalg.inv(np.eye(d) - W)\n",
    "            return X\n",
    "        else:\n",
    "            raise ValueError('population risk not available')\n",
    "    # empirical risk\n",
    "    G = ig.Graph.Weighted_Adjacency(W.tolist())\n",
    "    ordered_vertices = G.topological_sorting()\n",
    "    assert len(ordered_vertices) == d\n",
    "    X = np.zeros([n, d])\n",
    "    for j in ordered_vertices:\n",
    "        parents = G.neighbors(j, mode=ig.IN)\n",
    "        X[:, j] = _simulate_single_equation(X[:, parents], W[parents, j], scale_vec[j])\n",
    "    return X\n",
    "\n",
    "\n",
    "def simulate_nonlinear_sem(B, n, sem_type, noise_scale=None):\n",
    "    \"\"\"Simulate samples from nonlinear SEM.\n",
    "\n",
    "    Args:\n",
    "        B (np.ndarray): [d, d] binary adj matrix of DAG\n",
    "        n (int): num of samples\n",
    "        sem_type (str): mlp, mim, gp, gp-add\n",
    "        noise_scale (np.ndarray): scale parameter of additive noise, default all ones\n",
    "\n",
    "    Returns:\n",
    "        X (np.ndarray): [n, d] sample matrix\n",
    "    \"\"\"\n",
    "    def _simulate_single_equation(X, scale):\n",
    "        \"\"\"X: [n, num of parents], x: [n]\"\"\"\n",
    "        z = np.random.normal(scale=scale, size=n)\n",
    "        pa_size = X.shape[1]\n",
    "        if pa_size == 0:\n",
    "            return z\n",
    "        if sem_type == 'mlp':\n",
    "            hidden = 100\n",
    "            W1 = np.random.uniform(low=0.5, high=2.0, size=[pa_size, hidden])\n",
    "            W1[np.random.rand(*W1.shape) < 0.5] *= -1\n",
    "            W2 = np.random.uniform(low=0.5, high=2.0, size=hidden)\n",
    "            W2[np.random.rand(hidden) < 0.5] *= -1\n",
    "            x = sigmoid(X @ W1) @ W2 + z\n",
    "        elif sem_type == 'mim':\n",
    "            w1 = np.random.uniform(low=0.5, high=2.0, size=pa_size)\n",
    "            w1[np.random.rand(pa_size) < 0.5] *= -1\n",
    "            w2 = np.random.uniform(low=0.5, high=2.0, size=pa_size)\n",
    "            w2[np.random.rand(pa_size) < 0.5] *= -1\n",
    "            w3 = np.random.uniform(low=0.5, high=2.0, size=pa_size)\n",
    "            w3[np.random.rand(pa_size) < 0.5] *= -1\n",
    "            x = np.tanh(X @ w1) + np.cos(X @ w2) + np.sin(X @ w3) + z\n",
    "        elif sem_type == 'gp':\n",
    "            from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "            gp = GaussianProcessRegressor()\n",
    "            x = gp.sample_y(X, random_state=None).flatten() + z\n",
    "        elif sem_type == 'gp-add':\n",
    "            from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "            gp = GaussianProcessRegressor()\n",
    "            x = sum([gp.sample_y(X[:, i, None], random_state=None).flatten()\n",
    "                     for i in range(X.shape[1])]) + z\n",
    "        else:\n",
    "            raise ValueError('unknown sem type')\n",
    "        return x\n",
    "\n",
    "    d = B.shape[0]\n",
    "    scale_vec = noise_scale if noise_scale else np.ones(d)\n",
    "    X = np.zeros([n, d])\n",
    "    G = ig.Graph.Adjacency(B.tolist())\n",
    "    ordered_vertices = G.topological_sorting()\n",
    "    assert len(ordered_vertices) == d\n",
    "    for j in ordered_vertices:\n",
    "        parents = G.neighbors(j, mode=ig.IN)\n",
    "        X[:, j] = _simulate_single_equation(X[:, parents], scale_vec[j])\n",
    "    return X\n",
    "\n",
    "\n",
    "def count_accuracy(B_true, B_est):\n",
    "    \"\"\"Compute various accuracy metrics for B_est.\n",
    "\n",
    "    true positive = predicted association exists in condition in correct direction\n",
    "    reverse = predicted association exists in condition in opposite direction\n",
    "    false positive = predicted association does not exist in condition\n",
    "\n",
    "    Args:\n",
    "        B_true (np.ndarray): [d, d] ground truth graph, {0, 1}\n",
    "        B_est (np.ndarray): [d, d] estimate, {0, 1, -1}, -1 is undirected edge in CPDAG\n",
    "\n",
    "    Returns:\n",
    "        fdr: (reverse + false positive) / prediction positive\n",
    "        tpr: (true positive) / condition positive\n",
    "        fpr: (reverse + false positive) / condition negative\n",
    "        shd: undirected extra + undirected missing + reverse\n",
    "        nnz: prediction positive\n",
    "    \"\"\"\n",
    "    if (B_est == -1).any():  # cpdag\n",
    "        if not ((B_est == 0) | (B_est == 1) | (B_est == -1)).all():\n",
    "            raise ValueError('B_est should take value in {0,1,-1}')\n",
    "        if ((B_est == -1) & (B_est.T == -1)).any():\n",
    "            raise ValueError('undirected edge should only appear once')\n",
    "    else:  # dag\n",
    "        if not ((B_est == 0) | (B_est == 1)).all():\n",
    "            raise ValueError('B_est should take value in {0,1}')\n",
    "        if not is_dag(B_est):\n",
    "            raise ValueError('B_est should be a DAG')\n",
    "    d = B_true.shape[0]\n",
    "    # linear index of nonzeros\n",
    "    pred_und = np.flatnonzero(B_est == -1)\n",
    "    pred = np.flatnonzero(B_est == 1)\n",
    "    cond = np.flatnonzero(B_true)\n",
    "    cond_reversed = np.flatnonzero(B_true.T)\n",
    "    cond_skeleton = np.concatenate([cond, cond_reversed])\n",
    "    # true pos\n",
    "    true_pos = np.intersect1d(pred, cond, assume_unique=True)\n",
    "    # treat undirected edge favorably\n",
    "    true_pos_und = np.intersect1d(pred_und, cond_skeleton, assume_unique=True)\n",
    "    true_pos = np.concatenate([true_pos, true_pos_und])\n",
    "    # false pos\n",
    "    false_pos = np.setdiff1d(pred, cond_skeleton, assume_unique=True)\n",
    "    false_pos_und = np.setdiff1d(pred_und, cond_skeleton, assume_unique=True)\n",
    "    false_pos = np.concatenate([false_pos, false_pos_und])\n",
    "    # reverse\n",
    "    extra = np.setdiff1d(pred, cond, assume_unique=True)\n",
    "    reverse = np.intersect1d(extra, cond_reversed, assume_unique=True)\n",
    "    # compute ratio\n",
    "    pred_size = len(pred) + len(pred_und)\n",
    "    cond_neg_size = 0.5 * d * (d - 1) - len(cond)\n",
    "    fdr = float(len(reverse) + len(false_pos)) / max(pred_size, 1)\n",
    "    tpr = float(len(true_pos)) / max(len(cond), 1)\n",
    "    fpr = float(len(reverse) + len(false_pos)) / max(cond_neg_size, 1)\n",
    "    # structural hamming distance\n",
    "    pred_lower = np.flatnonzero(np.tril(B_est + B_est.T))\n",
    "    cond_lower = np.flatnonzero(np.tril(B_true + B_true.T))\n",
    "    extra_lower = np.setdiff1d(pred_lower, cond_lower, assume_unique=True)\n",
    "    missing_lower = np.setdiff1d(cond_lower, pred_lower, assume_unique=True)\n",
    "    shd = len(extra_lower) + len(missing_lower) + len(reverse)\n",
    "    return {'fdr': fdr, 'tpr': tpr, 'fpr': fpr, 'shd': shd, 'nnz': pred_size}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as slin\n",
    "import scipy.optimize as sopt\n",
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "\n",
    "def notears_linear(X, lambda1, loss_type, max_iter=100, h_tol=1e-8, rho_max=1e+16, w_threshold=0.3):\n",
    "    \"\"\"Solve min_W L(W; X) + lambda1 ‖W‖_1 s.t. h(W) = 0 using augmented Lagrangian.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): [n, d] sample matrix\n",
    "        lambda1 (float): l1 penalty parameter\n",
    "        loss_type (str): l2, logistic, poisson\n",
    "        max_iter (int): max num of dual ascent steps\n",
    "        h_tol (float): exit if |h(w_est)| <= htol\n",
    "        rho_max (float): exit if rho >= rho_max\n",
    "        w_threshold (float): drop edge if |weight| < threshold\n",
    "\n",
    "    Returns:\n",
    "        W_est (np.ndarray): [d, d] estimated DAG\n",
    "    \"\"\"\n",
    "    def _loss(W):\n",
    "        \"\"\"Evaluate value and gradient of loss.\"\"\"\n",
    "        M = X @ W\n",
    "        if loss_type == 'l2':\n",
    "            R = X - M\n",
    "            loss = 0.5 / X.shape[0] * (R ** 2).sum()\n",
    "            G_loss = - 1.0 / X.shape[0] * X.T @ R\n",
    "        elif loss_type == 'logistic':\n",
    "            loss = 1.0 / X.shape[0] * (np.logaddexp(0, M) - X * M).sum()\n",
    "            G_loss = 1.0 / X.shape[0] * X.T @ (sigmoid(M) - X)\n",
    "        elif loss_type == 'poisson':\n",
    "            S = np.exp(M)\n",
    "            loss = 1.0 / X.shape[0] * (S - X * M).sum()\n",
    "            G_loss = 1.0 / X.shape[0] * X.T @ (S - X)\n",
    "        else:\n",
    "            raise ValueError('unknown loss type')\n",
    "        return loss, G_loss\n",
    "\n",
    "    def _h(W):\n",
    "        \"\"\"Evaluate value and gradient of acyclicity constraint.\"\"\"\n",
    "        E = slin.expm(W * W)  # (Zheng et al. 2018)\n",
    "        h = np.trace(E) - d\n",
    "        #     # A different formulation, slightly faster at the cost of numerical stability\n",
    "        #     M = np.eye(d) + W * W / d  # (Yu et al. 2019)\n",
    "        #     E = np.linalg.matrix_power(M, d - 1)\n",
    "        #     h = (E.T * M).sum() - d\n",
    "        G_h = E.T * W * 2\n",
    "        return h, G_h\n",
    "\n",
    "    def _adj(w):\n",
    "        \"\"\"Convert doubled variables ([2 d^2] array) back to original variables ([d, d] matrix).\"\"\"\n",
    "        return (w[:d * d] - w[d * d:]).reshape([d, d])\n",
    "\n",
    "    def _func(w):\n",
    "        \"\"\"Evaluate value and gradient of augmented Lagrangian for doubled variables ([2 d^2] array).\"\"\"\n",
    "        W = _adj(w)\n",
    "        loss, G_loss = _loss(W)\n",
    "        h, G_h = _h(W)\n",
    "        obj = loss + 0.5 * rho * h * h + alpha * h + lambda1 * w.sum()\n",
    "        G_smooth = G_loss + (rho * h + alpha) * G_h\n",
    "        g_obj = np.concatenate((G_smooth + lambda1, - G_smooth + lambda1), axis=None)\n",
    "        return obj, g_obj\n",
    "\n",
    "    n, d = X.shape\n",
    "    w_est, rho, alpha, h = np.zeros(2 * d * d), 1.0, 0.0, np.inf  # double w_est into (w_pos, w_neg)\n",
    "    bnds = [(0, 0) if i == j else (0, None) for _ in range(2) for i in range(d) for j in range(d)]\n",
    "    if loss_type == 'l2':\n",
    "        X = X - np.mean(X, axis=0, keepdims=True)\n",
    "    for _ in range(max_iter):\n",
    "        w_new, h_new = None, None\n",
    "        while rho < rho_max:\n",
    "            sol = sopt.minimize(_func, w_est, method='L-BFGS-B', jac=True, bounds=bnds)\n",
    "            w_new = sol.x\n",
    "            h_new, _ = _h(_adj(w_new))\n",
    "            if h_new > 0.25 * h:\n",
    "                rho *= 10\n",
    "            else:\n",
    "                break\n",
    "        w_est, h = w_new, h_new\n",
    "        alpha += rho * h\n",
    "        if h <= h_tol or rho >= rho_max:\n",
    "            break\n",
    "    W_est = _adj(w_est)\n",
    "    W_est[np.abs(W_est) < w_threshold] = 0\n",
    "    return W_est\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0. , 0. , 0. ],\n",
       "       [0.2, 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0.3, 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0.5, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0.3, 0. ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.4 , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.35, 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.5 , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.3 , 0.  ]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.36499464, 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.30085123, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.45866795, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set_random_seed(1)\n",
    "\n",
    "n, d, s0, graph_type, sem_type = 10000, 5, 4, 'ER', 'gauss'\n",
    "# B_true = simulate_dag(d, s0, graph_type)\n",
    "# W_true = simulate_parameter(B_true)\n",
    "# print(W_true)\n",
    "\n",
    "X = simulate_linear_sem(A, n, sem_type)\n",
    "\n",
    "\n",
    "W_est = notears_linear(X, lambda1=0.05, loss_type='l2')\n",
    "W_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.28,  0.  , -0.  , -0.  ],\n",
       "       [ 0.  ,  0.  ,  0.22,  0.  , -0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.29,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.09,  0.  ,  0.  ],\n",
       "       [-0.  , -0.  ,  0.  ,  0.14,  0.  ]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "init =  np.array([[0,0,0,0,0],\n",
    "                [0, 0.0,0,0,0], \n",
    "                [0.2,0 , 0.0, 0,0], \n",
    "                [0.0, 0.0, 0, 0,0],\n",
    "                [0, 0, 0, 0.1, 0]])\n",
    "\n",
    "def likeli(param, X, alpha):\n",
    "    I = np.identity(X.shape[1])\n",
    "    A = np.reshape(param,(X.shape[1],X.shape[1]))\n",
    "    np.fill_diagonal(A,0)\n",
    "    IA_inv = np.linalg.inv(I-A)\n",
    "    return -np.sum(multivariate_normal.logpdf(X, mean = np.zeros(X.shape[1]), cov = np.dot(IA_inv, IA_inv.T))) + alpha*np.sum(np.abs(A))\n",
    "# likeli(z0[0].flatten(), theta[0], u0[0], rho, X)\n",
    "out = minimize(likeli, init.flatten(), args = (X, 0.15*X.shape[0]))\n",
    "np.set_printoptions(suppress=True)\n",
    "np.round(np.reshape(out.x, (5,5)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m I \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39midentity(X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m I \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49minv(W_true)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36minv\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DyGraph\\lib\\site-packages\\numpy\\linalg\\linalg.py:552\u001b[0m, in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    550\u001b[0m signature \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mD->D\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m isComplexType(t) \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39md->d\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    551\u001b[0m extobj \u001b[39m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[1;32m--> 552\u001b[0m ainv \u001b[39m=\u001b[39m _umath_linalg\u001b[39m.\u001b[39;49minv(a, signature\u001b[39m=\u001b[39;49msignature, extobj\u001b[39m=\u001b[39;49mextobj)\n\u001b[0;32m    553\u001b[0m \u001b[39mreturn\u001b[39;00m wrap(ainv\u001b[39m.\u001b[39mastype(result_t, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DyGraph\\lib\\site-packages\\numpy\\linalg\\linalg.py:89\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[1;32m---> 89\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m\"\u001b[39m\u001b[39mSingular matrix\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "I = np.identity(X.shape[1])\n",
    "I - np.linalg.inv(W_true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphical dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def soft_threshold_odd( A, lamda):\n",
    "\n",
    "    \"\"\"\n",
    "    diagonal lasso penalty\n",
    "\n",
    "    Parameters\n",
    "    ------------------\n",
    "    A: np.array,\n",
    "    \n",
    "    lamda: float,\n",
    "        regularization\n",
    "    \"\"\"\n",
    "    opt_m = (A-lamda)*(A>=lamda) + (A+lamda)*(A<=-lamda)\n",
    "    \n",
    "\n",
    "    return opt_m\n",
    "\n",
    "def gen_low_tri():\n",
    "    A = np.random.uniform(-0.5,0.5, size = (X.shape[1], X.shape[1]))\n",
    "    return np.tril(A,0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can I use scipy optim to find the DAG?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9186185569575491"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.cond(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.1 ,  0.  ,  0.  , -0.  ],\n",
       "       [-0.  ,  0.  ,  0.18,  0.  , -0.  ],\n",
       "       [-0.02,  0.  ,  0.  ,  0.14, -0.  ],\n",
       "       [-0.  , -0.01,  0.38,  0.  ,  0.02],\n",
       "       [ 0.  ,  0.  ,  0.02,  0.25,  0.  ]])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "init =  np.array([[0,0,0,0,0],\n",
    "                [0.1, 0.0,0,0,0], \n",
    "                [0.2,0.2 , 0.0, 0,0], \n",
    "                [0.0, 0.0, 0.1, 0,0],\n",
    "                [0, 0, 0, 0.1, 0]])\n",
    "\n",
    "def likeli(param, X, alpha):\n",
    "    I = np.identity(X.shape[1])\n",
    "    A = np.reshape(param,(X.shape[1],X.shape[1]))\n",
    "    np.fill_diagonal(A,0)\n",
    "    IA_inv = np.linalg.inv(I-A )\n",
    "    return -np.sum(multivariate_normal.logpdf(X, mean = np.zeros(X.shape[1]), cov = np.dot(IA_inv, IA_inv.T))) + alpha*np.sum(np.abs(A))\n",
    "# likeli(z0[0].flatten(), theta[0], u0[0], rho, X)\n",
    "out = minimize(likeli, init.flatten(), args = (X, 0.1*X.shape[0]))\n",
    "np.round(np.reshape(out.x, (5,5)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49671415, -0.03892147,  0.66581495,  1.86500053,  0.42793799],\n",
       "       [-0.23413696,  1.53238542,  1.21310214,  0.35991039,  0.89934859],\n",
       "       [-0.46341769, -0.55841329,  0.04663322, -1.98762816, -2.34351065],\n",
       "       ...,\n",
       "       [ 0.85958789, -0.21521307, -0.05839987, -0.01030584, -1.93347318],\n",
       "       [-0.01383775, -0.69249532, -0.70170168,  0.98849173, -1.09650146],\n",
       "       [ 0.81320519, -0.11632189, -0.26586443,  0.66438756,  0.50157226]])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3595.525322602367"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likeli(init.flatten(), X, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0 = np.array([ I- np.array([[0,0,0,0,0],\n",
    "                [1, 0,0,0,0], \n",
    "                [0, 1.0, 0, 0,0], \n",
    "                [0, 0.0, 1.0, 0,0],\n",
    "                [0, 0, 0, 1.0, 0]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.],\n",
       "       [-1.,  1.,  0.,  0.,  0.],\n",
       "       [ 0., -1.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., -1.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., -1.,  1.]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(z0[0].flatten(),(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.optimize import minimize\n",
    "def likeli(param,theta,u,rho, X):\n",
    "    param = np.reshape(param,(5,5))\n",
    "    IA_inv = np.linalg.inv(param)\n",
    "    return -np.sum(multivariate_normal.logpdf(X, mean = np.zeros(X.shape[1]), cov = np.dot(IA_inv, IA_inv.T))) + 0.5*rho*scipy.linalg.norm(theta - (I-param - u), ord = 'fro')**2\n",
    "\n",
    "# likeli(z0[0].flatten(), theta[0], u0[0], rho, X)\n",
    "out = minimize(likeli, z0[0].flatten(), args = (theta[0], u0[0], rho, X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function OptimizeResult.values>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "When `allow_singular is False`, the input matrix must be symmetric positive definite.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [209], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[0;32m     32\u001b[0m     theta[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m soft_threshold_odd(I\u001b[39m-\u001b[39mz0[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m u0[\u001b[39m0\u001b[39m], lamda\u001b[39m/\u001b[39mrho\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m     out \u001b[39m=\u001b[39m minimize(likeli, z0[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mflatten(), args \u001b[39m=\u001b[39;49m (theta[\u001b[39m0\u001b[39;49m], u0[\u001b[39m0\u001b[39;49m], rho, X))\n\u001b[0;32m     35\u001b[0m     z0[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(out\u001b[39m.\u001b[39mx, (\u001b[39m5\u001b[39m,\u001b[39m5\u001b[39m))\n\u001b[0;32m     37\u001b[0m     \u001b[39m# update z0\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     \u001b[39m# for _ in range(10):\u001b[39;00m\n\u001b[0;32m     39\u001b[0m         \u001b[39m#D = I#np.diag(np.reciprocal(np.diag(S)))\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m \n\u001b[0;32m     47\u001b[0m         \u001b[39m# update u\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DyGraph\\lib\\site-packages\\scipy\\optimize\\_minimize.py:694\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    692\u001b[0m     res \u001b[39m=\u001b[39m _minimize_cg(fun, x0, args, jac, callback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m    693\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbfgs\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 694\u001b[0m     res \u001b[39m=\u001b[39m _minimize_bfgs(fun, x0, args, jac, callback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m    695\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnewton-cg\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    696\u001b[0m     res \u001b[39m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    697\u001b[0m                              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DyGraph\\lib\\site-packages\\scipy\\optimize\\_optimize.py:1309\u001b[0m, in \u001b[0;36m_minimize_bfgs\u001b[1;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m   1306\u001b[0m pk \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39mdot(Hk, gfk)\n\u001b[0;32m   1307\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1308\u001b[0m     alpha_k, fc, gc, old_fval, old_old_fval, gfkp1 \u001b[39m=\u001b[39m \\\n\u001b[1;32m-> 1309\u001b[0m              _line_search_wolfe12(f, myfprime, xk, pk, gfk,\n\u001b[0;32m   1310\u001b[0m                                   old_fval, old_old_fval, amin\u001b[39m=\u001b[39;49m\u001b[39m1e-100\u001b[39;49m, amax\u001b[39m=\u001b[39;49m\u001b[39m1e100\u001b[39;49m)\n\u001b[0;32m   1311\u001b[0m \u001b[39mexcept\u001b[39;00m _LineSearchError:\n\u001b[0;32m   1312\u001b[0m     \u001b[39m# Line search failed to find a better solution.\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m     warnflag \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DyGraph\\lib\\site-packages\\scipy\\optimize\\_optimize.py:1087\u001b[0m, in \u001b[0;36m_line_search_wolfe12\u001b[1;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1074\u001b[0m \u001b[39mSame as line_search_wolfe1, but fall back to line_search_wolfe2 if\u001b[39;00m\n\u001b[0;32m   1075\u001b[0m \u001b[39msuitable step length is not found, and raise an exception if a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m \n\u001b[0;32m   1083\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m extra_condition \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mextra_condition\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 1087\u001b[0m ret \u001b[39m=\u001b[39m line_search_wolfe1(f, fprime, xk, pk, gfk,\n\u001b[0;32m   1088\u001b[0m                          old_fval, old_old_fval,\n\u001b[0;32m   1089\u001b[0m                          \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m ret[\u001b[39m0\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m extra_condition \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1092\u001b[0m     xp1 \u001b[39m=\u001b[39m xk \u001b[39m+\u001b[39m ret[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m pk\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DyGraph\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:84\u001b[0m, in \u001b[0;36mline_search_wolfe1\u001b[1;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, args, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mdot(gval[\u001b[39m0\u001b[39m], pk)\n\u001b[0;32m     82\u001b[0m derphi0 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(gfk, pk)\n\u001b[1;32m---> 84\u001b[0m stp, fval, old_fval \u001b[39m=\u001b[39m scalar_search_wolfe1(\n\u001b[0;32m     85\u001b[0m         phi, derphi, old_fval, old_old_fval, derphi0,\n\u001b[0;32m     86\u001b[0m         c1\u001b[39m=\u001b[39;49mc1, c2\u001b[39m=\u001b[39;49mc2, amax\u001b[39m=\u001b[39;49mamax, amin\u001b[39m=\u001b[39;49mamin, xtol\u001b[39m=\u001b[39;49mxtol)\n\u001b[0;32m     88\u001b[0m \u001b[39mreturn\u001b[39;00m stp, fc[\u001b[39m0\u001b[39m], gc[\u001b[39m0\u001b[39m], fval, old_fval, gval[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DyGraph\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:160\u001b[0m, in \u001b[0;36mscalar_search_wolfe1\u001b[1;34m(phi, derphi, phi0, old_phi0, derphi0, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[39mif\u001b[39;00m task[:\u001b[39m2\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFG\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    159\u001b[0m     alpha1 \u001b[39m=\u001b[39m stp\n\u001b[1;32m--> 160\u001b[0m     phi1 \u001b[39m=\u001b[39m phi(stp)\n\u001b[0;32m    161\u001b[0m     derphi1 \u001b[39m=\u001b[39m derphi(stp)\n\u001b[0;32m    162\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DyGraph\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:75\u001b[0m, in \u001b[0;36mline_search_wolfe1.<locals>.phi\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mphi\u001b[39m(s):\n\u001b[0;32m     74\u001b[0m     fc[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m f(xk \u001b[39m+\u001b[39;49m s\u001b[39m*\u001b[39;49mpk, \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DyGraph\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:267\u001b[0m, in \u001b[0;36mScalarFunction.fun\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39marray_equal(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx):\n\u001b[0;32m    266\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 267\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun()\n\u001b[0;32m    268\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DyGraph\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated:\n\u001b[1;32m--> 251\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun_impl()\n\u001b[0;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DyGraph\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fun\u001b[39m():\n\u001b[1;32m--> 155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DyGraph\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    138\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "Cell \u001b[1;32mIn [209], line 25\u001b[0m, in \u001b[0;36mlikeli\u001b[1;34m(param, theta, u, rho, X)\u001b[0m\n\u001b[0;32m     23\u001b[0m param \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(param,(\u001b[39m5\u001b[39m,\u001b[39m5\u001b[39m))\n\u001b[0;32m     24\u001b[0m IA_inv \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39minv(param\u001b[39m+\u001b[39m\u001b[39m0.1\u001b[39m\u001b[39m*\u001b[39mI)\n\u001b[1;32m---> 25\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39msum(multivariate_normal\u001b[39m.\u001b[39;49mlogpdf(X, mean \u001b[39m=\u001b[39;49m np\u001b[39m.\u001b[39;49mzeros(X\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m]), cov \u001b[39m=\u001b[39;49m np\u001b[39m.\u001b[39;49mdot(IA_inv, IA_inv\u001b[39m.\u001b[39;49mT))) \u001b[39m+\u001b[39m \u001b[39m0.5\u001b[39m\u001b[39m*\u001b[39mrho\u001b[39m*\u001b[39mscipy\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(theta \u001b[39m-\u001b[39m (I\u001b[39m-\u001b[39mparam \u001b[39m-\u001b[39m u), \u001b[39mord\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mfro\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DyGraph\\lib\\site-packages\\scipy\\stats\\_multivariate.py:513\u001b[0m, in \u001b[0;36mmultivariate_normal_gen.logpdf\u001b[1;34m(self, x, mean, cov, allow_singular)\u001b[0m\n\u001b[0;32m    511\u001b[0m dim, mean, cov \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_parameters(\u001b[39mNone\u001b[39;00m, mean, cov)\n\u001b[0;32m    512\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_quantiles(x, dim)\n\u001b[1;32m--> 513\u001b[0m psd \u001b[39m=\u001b[39m _PSD(cov, allow_singular\u001b[39m=\u001b[39;49mallow_singular)\n\u001b[0;32m    514\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logpdf(x, mean, psd\u001b[39m.\u001b[39mU, psd\u001b[39m.\u001b[39mlog_pdet, psd\u001b[39m.\u001b[39mrank)\n\u001b[0;32m    515\u001b[0m \u001b[39mif\u001b[39;00m allow_singular \u001b[39mand\u001b[39;00m (psd\u001b[39m.\u001b[39mrank \u001b[39m<\u001b[39m dim):\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DyGraph\\lib\\site-packages\\scipy\\stats\\_multivariate.py:167\u001b[0m, in \u001b[0;36m_PSD.__init__\u001b[1;34m(self, M, cond, rcond, lower, check_finite, allow_singular)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(d) \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(s) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_singular:\n\u001b[0;32m    165\u001b[0m     msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mWhen `allow_singular is False`, the input matrix must be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    166\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39msymmetric positive definite.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 167\u001b[0m     \u001b[39mraise\u001b[39;00m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mLinAlgError(msg)\n\u001b[0;32m    168\u001b[0m s_pinv \u001b[39m=\u001b[39m _pinv_1d(s, eps)\n\u001b[0;32m    169\u001b[0m U \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmultiply(u, np\u001b[39m.\u001b[39msqrt(s_pinv))\n",
      "\u001b[1;31mLinAlgError\u001b[0m: When `allow_singular is False`, the input matrix must be symmetric positive definite."
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "d = X.shape[1]\n",
    "I = np.identity(X.shape[1])\n",
    "\n",
    "u0 = np.zeros((1, X.shape[1], X.shape[1]))\n",
    "\n",
    "z0 = np.array([ I- np.array([[0,0,0,0,0],\n",
    "                [1, 0,0,0,0], \n",
    "                [0, 1.0, 0, 0,0], \n",
    "                [0, 0.0, 1.0, 0,0],\n",
    "                [0, 0, 0, 1.0, 0]]) for  i in range(1)]) # np.array([gen_low_tri() for  i in range(1)])\n",
    "theta = np.array([I-z0[i] for i in range(1) ])\n",
    "rho = obs_per_graph\n",
    "\n",
    "lamda = 0.1*obs_per_graph\n",
    "grad_val = 0.0001\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def likeli(param,theta,u,rho, X):\n",
    "    param = np.reshape(param,(5,5))\n",
    "    IA_inv = np.linalg.inv(param+0.1*I)\n",
    "    return -np.sum(multivariate_normal.logpdf(X, mean = np.zeros(X.shape[1]), cov = np.dot(IA_inv, IA_inv.T))) + 0.5*rho*scipy.linalg.norm(theta - (I-param - u), ord = 'fro')**2\n",
    "\n",
    "# likeli(z0[0].flatten(), theta[0], u0[0], rho, X)\n",
    "out = minimize(likeli, z0[0].flatten(), args = (theta[0], u0[0], rho, X))\n",
    "\n",
    "S = np.cov(X.T)\n",
    "for _ in range(100):\n",
    "    theta[0] = soft_threshold_odd(I-z0[0] - u0[0], lamda/rho/2)\n",
    "\n",
    "    out = minimize(likeli, z0[0].flatten(), args = (theta[0], u0[0], rho, X))\n",
    "    z0[0] = np.reshape(out.x, (5,5))\n",
    "\n",
    "    # update z0\n",
    "    # for _ in range(10):\n",
    "        #D = I#np.diag(np.reciprocal(np.diag(S)))\n",
    "        #z0_inv = np.linalg.inv(z0[0])\n",
    "        # grad = -2*z0_inv+ 2*np.dot(S, z0[0]).dot(D) +(rho/obs_per_graph)*(theta[0] - (I-z0[0] - u0[0]))\n",
    "        # grad[np.triu_indices(grad.shape[0],1)] = 0\n",
    "        \n",
    "        #z0[0] = z0[0] - grad_val*grad\n",
    "\n",
    "\n",
    "        # update u\n",
    "    \n",
    "    u0[0] = u0[0] - I + z0[0] + theta[0]\n",
    "\n",
    "np.round(theta[0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[162.36792171,  -7.95482257, -50.6309705 ,  23.75315392,\n",
       "         -3.11848664],\n",
       "       [-41.61902933,  -4.49426347, -51.58031127, -19.13683909,\n",
       "          4.04156967],\n",
       "       [-22.38183906, -96.9310238 ,  27.53178121,  14.30404917,\n",
       "         -2.62742009],\n",
       "       [-45.3551515 ,  54.24817921,  -9.22244245,  31.50411667,\n",
       "         -4.75022752],\n",
       "       [-23.58393822,  -9.36156141,   4.76379784,  57.26673727,\n",
       "         -7.42120051]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3844.3496059059335"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "IA_inv = np.linalg.inv(I -A)\n",
    "-np.sum(multivariate_normal.logpdf(X, mean = np.zeros(X.shape[1]), cov = np.dot(IA_inv, IA_inv.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.23840555, -0.10254184, -0.07240881, -0.08055169, -0.10856816],\n",
       "       [-0.1638453 ,  1.07915162, -0.11665455, -0.05702967, -0.17342124],\n",
       "       [-0.0480302 , -0.1866373 ,  1.17819159, -0.11247163, -0.26681838],\n",
       "       [-0.08474864, -0.03878493, -0.22568925,  1.15375003, -0.36213351],\n",
       "       [-0.10919724, -0.16970385, -0.22009608, -0.40758308,  0.79950642]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z0[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No tears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_per_graph = 500\n",
    "X = np.zeros((obs_per_graph, 5))\n",
    "sigma = 0.1\n",
    "rnd = np.random.RandomState(42)\n",
    "for i in range(obs_per_graph):\n",
    "    X[i,0] = 1 # rnd.normal(0,1)\n",
    "    X[i,1] = 0.7*X[i,0] + rnd.normal(0,sigma)\n",
    "    X[i,2] = 0.5*X[i,0] + rnd.normal(0,sigma)\n",
    "    X[i,3] = 0.45*X[i,1] + 0.3*X[i,2] + rnd.normal(0,sigma)\n",
    "    X[i,4] =  0.6*X[i,2] + rnd.normal(0,sigma)\n",
    "\n",
    "\n",
    "theta_true = np.array([[1,0,0,0,0],\n",
    "                       [0.7, 1,0,0,0], \n",
    "                       [0.5, 0, 1, 0,0], \n",
    "                       [0, 0.45, 0.3, 1,0],\n",
    "                       [0, 0, 0.6, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027735178609331612\n",
      "theta\n",
      "[[ 0.   -0.19  0.25 -0.33 -0.46]\n",
      " [-0.11  0.    0.24 -0.28 -0.42]\n",
      " [ 0.1  -0.18  0.   -0.26 -0.36]\n",
      " [ 0.08 -0.16  0.2   0.   -0.37]\n",
      " [ 0.12 -0.17  0.1  -0.23  0.  ]]\n",
      "z0\n",
      "[[ 0.   -0.19  0.25 -0.33 -0.46]\n",
      " [-0.11  0.    0.24 -0.28 -0.42]\n",
      " [ 0.1  -0.18  0.   -0.26 -0.36]\n",
      " [ 0.08 -0.16  0.2   0.   -0.37]\n",
      " [ 0.12 -0.17  0.1  -0.23  0.  ]]\n",
      "z1\n",
      "[[ 0.   -0.2   0.25 -0.32 -0.5 ]\n",
      " [-0.11  0.    0.24 -0.28 -0.45]\n",
      " [ 0.1  -0.19  0.   -0.26 -0.37]\n",
      " [ 0.08 -0.17  0.2   0.   -0.39]\n",
      " [ 0.12 -0.18  0.1  -0.23  0.  ]]\n"
     ]
    }
   ],
   "source": [
    "def _h(W):\n",
    "    \"\"\"Evaluate value and gradient of acyclicity constraint.\"\"\"\n",
    "    E = expm(W * W)  # (Zheng et al. 2018)\n",
    "    h = np.trace(E) - W.shape[0]\n",
    "    #     # A different formulation, slightly faster at the cost of numerical stability\n",
    "    #     M = np.eye(d) + W * W / d  # (Yu et al. 2019)\n",
    "    #     E = np.linalg.matrix_power(M, d - 1)\n",
    "    #     h = (E.T * M).sum() - d\n",
    "    G_h = E.T * W * 2\n",
    "    return h, G_h\n",
    "\n",
    "\n",
    "from scipy.linalg import expm\n",
    "\n",
    "I = np.identity(X.shape[1])\n",
    "d = X.shape[1]\n",
    "\n",
    "u0 = 0.1*np.ones((1, X.shape[1], X.shape[1]))\n",
    "np.fill_diagonal(u0[0],0)\n",
    "u1 = 0.1*np.zeros((1, X.shape[1], X.shape[1]))\n",
    "np.fill_diagonal(u1[0],0)\n",
    "\n",
    "# np.random.uniform(0,0.5,size=(d,d))\n",
    "z0 = np.array([theta_true for  i in range(1)])\n",
    "z1 = np.array([theta_true for  i in range(1)])\n",
    "theta = np.array([theta_true for i in range(1) ])\n",
    "np.fill_diagonal(z0[0],0)\n",
    "np.fill_diagonal(z1[0],0)\n",
    "np.fill_diagonal(theta[0],0)\n",
    "rho = 0.001  # obs_per_graph\n",
    "\n",
    "lamda = 0.2*rho\n",
    "grad_val = 0.1\n",
    "\n",
    "S = np.dot(X.T,X)/500\n",
    "for _ in range(1000):\n",
    "\n",
    "    S_inv = np.linalg.inv(S +2*rho*I)\n",
    "    theta[0] =  np.dot(S_inv, S + rho*z0[0]+ rho*z1[0]- rho*u0[0]- rho*u1[0])\n",
    "    np.fill_diagonal(theta[0],0)\n",
    "    \n",
    "    z0[0] = soft_threshold_odd(theta[0] + u0[0], lamda/rho)\n",
    "\n",
    "    #     # update z1\n",
    "    for _ in range(50):\n",
    "        h , _ = _h(z1[0])\n",
    "        grad =  2*h*2*expm(z1[0] * z1[0])*z1[0] + (rho/10)*(theta[0]-z1[0]+u1[0])\n",
    "        z1[0] = z1[0] - grad_val*grad\n",
    "\n",
    "\n",
    "    # update u\n",
    "    u0[0] = u0[0] + theta[0]-z0[0]\n",
    "    u1[0] = u1[0] + theta[0]-z1[0]\n",
    "\n",
    "\n",
    "\n",
    "h_val, _ = _h(theta[0])\n",
    "print(h_val)\n",
    "np.set_printoptions(suppress=True)\n",
    "print(\"theta\")\n",
    "print(np.round(theta[0],2))\n",
    "print(\"z0\")\n",
    "print(np.round(z0[0],2))\n",
    "print(\"z1\")\n",
    "print(np.round(z1[0],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8997736426727307"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.linalg.norm(X-np.dot(X,theta[0]))**2/obs_per_graph/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9399088 , 0.66157758, 0.52692463, 0.47697861, 0.29346212],\n",
       "       [0.66157758, 1.54265381, 0.37910093, 0.76550327, 0.25216049],\n",
       "       [0.52692463, 0.37910093, 1.19323098, 0.53570081, 0.72616871],\n",
       "       [0.47697861, 0.76550327, 0.53570081, 1.39875979, 0.29958836],\n",
       "       [0.29346212, 0.25216049, 0.72616871, 0.29958836, 1.44661653]])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " array([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.fill_diagonal(theta_true,0)\n",
    "_h(theta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3300910227002849"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_true\n",
    "scipy.linalg.norm(X-np.dot(X,theta_true))**2/obs_per_graph/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1479587766404544"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.linalg.norm(X-np.dot(X,theta[0]))**2/obs_per_graph/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " array([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "_h(theta_true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DyGraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95fbe69513d588cbfb572e93f5d450d181f1d8d49af9eba3df43ef2e3376dba8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
