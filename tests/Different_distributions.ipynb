{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys,os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_t as mvt, norm \n",
    "import sklearn\n",
    "from sklearn.covariance import GraphicalLasso\n",
    "import scipy\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "import time\n",
    "import tqdm\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': 25,\n",
    "         'axes.labelsize': 25,\n",
    "         'axes.titlesize':25,\n",
    "         'xtick.labelsize':25,\n",
    "         'ytick.labelsize':'x-large',\n",
    "          'axes.titlesize' : 'x-large'}\n",
    "pylab.rcParams.update(params)\n",
    "sys.path.insert(0, 'C:/Users/User/Code/DyGraph')\n",
    "\n",
    "import DyGraph as dg\n",
    "\n",
    "from sklearn.datasets import make_sparse_spd_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_one_zero_error(T,Estimate, ratio = True):\n",
    "    d = T.shape[0]\n",
    "    T[np.abs(T)<1e-7] = 0.0\n",
    "    Estimate[np.abs(Estimate)<1e-7] = 0.0\n",
    "    error = np.sum(~(np.sign(T[np.triu_indices(T.shape[0], k = 1)]) == np.sign(Estimate[np.triu_indices(Estimate.shape[0], k = 1)])))\n",
    "    if ratio:\n",
    "        error = error/float(d*(d-1)/2)\n",
    "    return error\n",
    "\n",
    "def calc_f1(T,Estimate):\n",
    "    d = T.shape[0]\n",
    "    T[np.abs(T)<1e-7] = 0.0\n",
    "    Estimate[np.abs(Estimate)<1e-7] = 0.0\n",
    "    y_true = np.abs(np.sign(T[np.triu_indices(d, 1)]))\n",
    "    y_pred = np.abs(np.sign(Estimate[np.triu_indices(d, 1)]))\n",
    "    return sklearn.metrics.f1_score(y_true,y_pred)\n",
    "\n",
    "def calc_f1(T,Estimate):\n",
    "    d = T.shape[0]\n",
    "    T[np.abs(T)<1e-7] = 0.0\n",
    "    Estimate[np.abs(Estimate)<1e-7] = 0.0\n",
    "    y_true = np.abs(np.sign(T[np.triu_indices(d, 1)]))\n",
    "    y_pred = np.abs(np.sign(Estimate[np.triu_indices(d, 1)]))\n",
    "    return sklearn.metrics.f1_score(y_true,y_pred)\n",
    "\n",
    "def calc_precision(T,Estimate):\n",
    "    d = T.shape[0]\n",
    "    T[np.abs(T)<1e-7] = 0.0\n",
    "    Estimate[np.abs(Estimate)<1e-7] = 0.0\n",
    "    y_true = np.abs(np.sign(T[np.triu_indices(d, 1)]))\n",
    "    y_pred = np.abs(np.sign(Estimate[np.triu_indices(d, 1)]))\n",
    "    return sklearn.metrics.precision_score(y_true,y_pred)\n",
    "\n",
    "def calc_recall(T,Estimate):\n",
    "    d = T.shape[0]\n",
    "    T[np.abs(T)<1e-7] = 0.0\n",
    "    Estimate[np.abs(Estimate)<1e-7] = 0.0\n",
    "    y_true = np.abs(np.sign(T[np.triu_indices(d, 1)]))\n",
    "    y_pred = np.abs(np.sign(Estimate[np.triu_indices(d, 1)]))\n",
    "    return sklearn.metrics.recall_score(y_true,y_pred)\n",
    "\n",
    "def calc_density(prec):\n",
    "    tmp = prec.copy()\n",
    "    np.fill_diagonal(tmp,0)\n",
    "    G = nx.from_numpy_array(tmp)\n",
    "    # G = nx.fast_gnp_random_graph(300,0.3)\n",
    "    return nx.density(G)\n",
    "\n",
    "def calc_roc(T,Estimate):\n",
    "    d = T.shape[0]\n",
    "    T[np.abs(T)<1e-7] = 0.0\n",
    "    Estimate[np.abs(Estimate)<1e-7] = 0.0\n",
    "    y_true = np.abs(np.sign(T[np.triu_indices(d, 1)]))\n",
    "    y_pred = np.abs(np.sign(Estimate[np.triu_indices(d, 1)]))\n",
    "    return sklearn.metrics.recall_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260.51168481012627\n",
      "0.5559183673469388\n",
      "precision\n",
      "[[ 1.         -0.16466916 -0.23081246 ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.16466916  1.         -0.09466553 ...  0.          0.13315111\n",
      "   0.25059233]\n",
      " [-0.23081246 -0.09466553  1.         ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  1.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.13315111  0.         ...  0.          1.\n",
      "   0.        ]\n",
      " [ 0.          0.25059233  0.         ...  0.          0.\n",
      "   1.        ]]\n",
      "Covariance\n",
      "[[ 3.33140932 -0.25692045  1.10967945 ...  0.3199703  -0.8543497\n",
      "   0.19986897]\n",
      " [-0.25692045  4.59401228 -0.09227131 ... -0.99734698 -2.72228913\n",
      "  -0.97043293]\n",
      " [ 1.10967945 -0.09227131  3.11474081 ...  1.01690112  0.60505175\n",
      "   0.98034227]\n",
      " ...\n",
      " [ 0.3199703  -0.99734698  1.01690112 ...  4.10090314  0.61848376\n",
      "   2.03202162]\n",
      " [-0.8543497  -2.72228913  0.60505175 ...  0.61848376  7.12912669\n",
      "   1.48473521]\n",
      " [ 0.19986897 -0.97043293  0.98034227 ...  2.03202162  1.48473521\n",
      "   9.36433925]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prec_0 = make_sparse_spd_matrix(50, alpha=0.8, smallest_coef=-0.8, largest_coef=0.8, norm_diag = True,random_state=42)\n",
    "print(np.linalg.cond(prec_0))\n",
    "tmp = prec_0.copy()\n",
    "np.fill_diagonal(tmp,0)\n",
    "G = nx.from_numpy_array(tmp)\n",
    "print(nx.density(G))\n",
    "print(\"precision\")\n",
    "print(prec_0)\n",
    "print(\"Covariance\")\n",
    "S = np.linalg.inv(prec_0)\n",
    "print(S)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVT - MVT vs Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]C:\\Users/User/Code/DyGraph\\DyGraph\\dygl_parallel.py:109: UserWarning: EM algorithm did not converge. Try to increase number of iterations\n",
      "  warnings.warn(\"EM algorithm did not converge. Try to increase number of iterations\")\n",
      "Error 1.02E-10:   4%|▎         | 358/10000 [00:00<00:20, 475.93it/s]\n",
      "Error 1.07E-10:   2%|▏         | 210/10000 [00:00<00:14, 694.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0.8888888888888888\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error 1.00E-10:   9%|▉         | 922/10000 [00:02<00:21, 419.36it/s]\n",
      "Error 1.01E-10:   8%|▊         | 845/10000 [00:01<00:14, 646.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "0.5559183673469388\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error 7.30E-3:   1%|          | 96/10000 [00:01<02:13, 74.04it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     42\u001b[0m dg_opt1 \u001b[39m=\u001b[39m dg\u001b[39m.\u001b[39mdygl_parallel(obs_per_graph \u001b[39m=\u001b[39m obs_per_graph, max_iter \u001b[39m=\u001b[39m \u001b[39m10000\u001b[39m, lamda \u001b[39m=\u001b[39m obs_per_graph\u001b[39m*\u001b[39malpha, kappa \u001b[39m=\u001b[39m obs_per_graph\u001b[39m*\u001b[39mkappa, tol \u001b[39m=\u001b[39m tol)\n\u001b[1;32m---> 43\u001b[0m dg_opt1\u001b[39m.\u001b[39;49mfit(X, nr_workers\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, temporal_penalty\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39melement-wise\u001b[39;49m\u001b[39m\"\u001b[39;49m, lik_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mt\u001b[39;49m\u001b[39m\"\u001b[39;49m, nr_em_itr \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, time_index\u001b[39m=\u001b[39;49m\u001b[39mrange\u001b[39;49m(X\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]), nu \u001b[39m=\u001b[39;49m \u001b[39m4\u001b[39;49m, em_tol \u001b[39m=\u001b[39;49m \u001b[39m1e-6\u001b[39;49m)\n\u001b[0;32m     44\u001b[0m elapsed \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\u001b[39m-\u001b[39mstart\n\u001b[0;32m     45\u001b[0m dens_inner\u001b[39m.\u001b[39mappend(nx\u001b[39m.\u001b[39mdensity(G))\n",
      "File \u001b[1;32mC:\\Users/User/Code/DyGraph\\DyGraph\\dygl_parallel.py:343\u001b[0m, in \u001b[0;36mdygl_parallel.fit\u001b[1;34m(self, X, temporal_penalty, lik_type, nr_workers, verbose, time_index, **kwargs)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    342\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnr_graphs):\n\u001b[1;32m--> 343\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtheta[i],_ \u001b[39m=\u001b[39m theta_update(i,\n\u001b[0;32m    344\u001b[0m                                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_A(i), \n\u001b[0;32m    345\u001b[0m                                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mS[i], \n\u001b[0;32m    346\u001b[0m                                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobs_per_graph_used[i],\n\u001b[0;32m    347\u001b[0m                                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrho, \n\u001b[0;32m    348\u001b[0m                                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnr_graphs,\n\u001b[0;32m    349\u001b[0m                                             kwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mgroups\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    350\u001b[0m                                             lik_type,\n\u001b[0;32m    351\u001b[0m                                             X[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobs_per_graph\u001b[39m*\u001b[39;49mi:(i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobs_per_graph],\n\u001b[0;32m    352\u001b[0m                                             kwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mnr_em_itr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m5\u001b[39;49m),\n\u001b[0;32m    353\u001b[0m                                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtheta[i],\n\u001b[0;32m    354\u001b[0m                                             kwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mnu\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m4\u001b[39;49m),\n\u001b[0;32m    355\u001b[0m                                             kwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mem_tol\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m1e-4\u001b[39;49m))\n\u001b[0;32m    358\u001b[0m \u001b[39m# update dual in parallel\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[39m# update z0\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnr_graphs):\n",
      "File \u001b[1;32mC:\\Users/User/Code/DyGraph\\DyGraph\\dygl_parallel.py:167\u001b[0m, in \u001b[0;36mtheta_update\u001b[1;34m(i, A, S, n_t, rho, nr_graphs, groups, lik_type, X, nr_em_itr, theta_init, nu, em_tol)\u001b[0m\n\u001b[0;32m    165\u001b[0m     theta \u001b[39m=\u001b[39m Gaussian_update(S, A, eta)\n\u001b[0;32m    166\u001b[0m \u001b[39melif\u001b[39;00m lik_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 167\u001b[0m     theta \u001b[39m=\u001b[39m inner_em(X, A, theta_init, nu, rho, eta, nr_itr\u001b[39m=\u001b[39;49m nr_em_itr, tol \u001b[39m=\u001b[39;49m em_tol)\n\u001b[0;32m    168\u001b[0m \u001b[39melif\u001b[39;00m lik_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgroup-t\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    169\u001b[0m     \u001b[39m# print(\"group-t update\")\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     theta \u001b[39m=\u001b[39m inner_em(X, A, theta_init, nu, rho, eta, groups, lik_type \u001b[39m=\u001b[39m lik_type, nr_itr\u001b[39m=\u001b[39m nr_em_itr, tol \u001b[39m=\u001b[39m em_tol)\n",
      "File \u001b[1;32mC:\\Users/User/Code/DyGraph\\DyGraph\\dygl_parallel.py:95\u001b[0m, in \u001b[0;36minner_em\u001b[1;34m(X, A, theta_init, nu, rho, eta, groups, lik_type, nr_itr, tol)\u001b[0m\n\u001b[0;32m     93\u001b[0m M \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39meinsum(\u001b[39m'\u001b[39m\u001b[39mnj,jk,nk->n\u001b[39m\u001b[39m'\u001b[39m, x, theta_pre, x)  \u001b[39m# Mahalanobis distance\u001b[39;00m\n\u001b[0;32m     94\u001b[0m tau \u001b[39m=\u001b[39m (nu \u001b[39m+\u001b[39m d)\u001b[39m/\u001b[39m(nu  \u001b[39m+\u001b[39m M)\n\u001b[1;32m---> 95\u001b[0m S \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49meinsum(\u001b[39m'\u001b[39;49m\u001b[39mnj,n,nk->jk\u001b[39;49m\u001b[39m'\u001b[39;49m, x, tau, x)\u001b[39m/\u001b[39m\u001b[39mfloat\u001b[39m(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m     96\u001b[0m \u001b[39m# M-step\u001b[39;00m\n\u001b[0;32m     97\u001b[0m theta_new\u001b[39m=\u001b[39m Gaussian_update(S, A, eta)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DyGraph\\lib\\site-packages\\numpy\\core\\einsumfunc.py:1371\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[0;32m   1369\u001b[0m     \u001b[39mif\u001b[39;00m specified_out:\n\u001b[0;32m   1370\u001b[0m         kwargs[\u001b[39m'\u001b[39m\u001b[39mout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m out\n\u001b[1;32m-> 1371\u001b[0m     \u001b[39mreturn\u001b[39;00m c_einsum(\u001b[39m*\u001b[39moperands, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1373\u001b[0m \u001b[39m# Check the kwargs to avoid a more cryptic error later, without having to\u001b[39;00m\n\u001b[0;32m   1374\u001b[0m \u001b[39m# repeat default values here\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m valid_einsum_kwargs \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39morder\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcasting\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ds = [5, 10, 50, 100]\n",
    "alpha_prob = [0.03, 0.15, 0.8, 0.9] #[0.03, 0.15, 0.5, 0.7, 0.8, 0.9, 0.95, 0.97, 0.99 ]\n",
    "alpha = 0.05\n",
    "kappa = 0.1\n",
    "tol = 1e-10\n",
    "n = 1000\n",
    "obs_per_graph = 100\n",
    "prec_dict ={}\n",
    "\n",
    "dens_inner = []\n",
    "time_inner = []\n",
    "F_inner = []\n",
    "zo_inner = []\n",
    "l1_inner = []\n",
    "\n",
    "dens_outer = []\n",
    "time_outer = []\n",
    "F_outer = []\n",
    "zo_outer = []\n",
    "l1_outer = []\n",
    "\n",
    "\n",
    "for i,d in enumerate(ds):\n",
    "    print(d)\n",
    "\n",
    "    prec = make_sparse_spd_matrix(d, alpha=alpha_prob[i], smallest_coef=-0.9, largest_coef=0.9, norm_diag = True, random_state = 42)\n",
    "    tmp = prec.copy()\n",
    "    np.fill_diagonal(tmp,0)\n",
    "    G = nx.from_numpy_array(tmp)\n",
    "    print(nx.density(G))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    prec_dict[i] = prec\n",
    "\n",
    "\n",
    "    X1 = mvt.rvs(shape = np.linalg.inv(prec),  df = 4, size = n) # np.random.multivariate_normal(mean = np.zeros(prec.shape[0]),cov = np.linalg.inv(prec), size = n)\n",
    "    X = X1\n",
    "\n",
    "\n",
    "\n",
    "    start = time.time()\n",
    "    dg_opt1 = dg.dygl_parallel(obs_per_graph = obs_per_graph, max_iter = 10000, lamda = obs_per_graph*alpha, kappa = obs_per_graph*kappa, tol = tol)\n",
    "    dg_opt1.fit(X, nr_workers=1, temporal_penalty=\"element-wise\", lik_type=\"t\", nr_em_itr = 1, time_index=range(X.shape[0]), nu = 4, em_tol = 1e-6)\n",
    "    elapsed = time.time()-start\n",
    "    dens_inner.append(nx.density(G))\n",
    "    time_inner.append(elapsed)\n",
    "\n",
    "    zo_inner.append(np.mean([calc_one_zero_error(prec, dg_opt1.theta[k]) for k in range(len(dg_opt1.theta))]))\n",
    "    F_inner.append(np.mean([scipy.linalg.norm(prec-dg_opt1.theta[k], ord = 'fro')/scipy.linalg.norm(prec, ord = 'fro') for k in range(len(dg_opt1.theta))]))\n",
    "    l1_inner.append(np.mean([scipy.linalg.norm(prec-dg_opt1.theta[k], ord = 1)/scipy.linalg.norm(prec, ord = 1) for k in range(len(dg_opt1.theta))]))\n",
    "        \n",
    "    start = time.time()\n",
    "    dg_opt1 = dg.dygl_parallel(obs_per_graph = obs_per_graph, max_iter = 10000, lamda = obs_per_graph*alpha, kappa = obs_per_graph*kappa, tol = tol)\n",
    "    dg_opt1.fit(X, nr_workers=1, temporal_penalty=\"element-wise\", lik_type=\"gaussian\", time_index=range(X.shape[0]))\n",
    "    elapsed = time.time()-start\n",
    "    dens_outer.append(nx.density(G))\n",
    "    time_outer.append(elapsed)\n",
    "\n",
    "    zo_outer.append(np.mean([calc_one_zero_error(prec, dg_opt1.theta[k]) for k in range(len(dg_opt1.theta))]))\n",
    "    F_outer.append(np.mean([scipy.linalg.norm(prec-dg_opt1.theta[k], ord = 'fro')/scipy.linalg.norm(prec, ord = 'fro') for k in range(len(dg_opt1.theta))]))\n",
    "    l1_outer.append(np.mean([scipy.linalg.norm(prec-dg_opt1.theta[k], ord = 1)/scipy.linalg.norm(prec, ord = 1) for k in range(len(dg_opt1.theta))]))\n",
    "\n",
    "out_dict = {'nr_obs_per_graph':obs_per_graph, 'n':n, 'temporal_penalty':'global-reconstruction', \n",
    "'density_inner':dens_inner, 'tol':tol, 'time_inner':time_inner, 'zo_inner':zo_inner, 'F_inner':F_inner, 'l1_inner':l1_inner,\n",
    "'density_outer':dens_outer, 'tol':tol, 'time_outer':time_outer, 'zo_outer':zo_outer, 'F_inner':F_outer, 'l1_inner':l1_outer,\n",
    "'ds':ds, 'alpha':alpha, 'kappa':kappa, 'max_iter':5000} \n",
    "    \n",
    "import pickle\n",
    "with open(f'../distributions/mvt_mvt_gaussian.pkl', 'wb') as handle:\n",
    "    pickle.dump(out_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (14,5))\n",
    "\n",
    "ax[0].plot(ds, time_inner, label  = 'Inner EM')\n",
    "ax[0].plot(ds, time_outer, label  = 'Outer EM')\n",
    "ax[0].set_xlabel(\"Dimension\", fontdict = {'fontsize':24})\n",
    "ax[0].set_ylabel(\"Seconds\", fontdict = {'fontsize':24})\n",
    "ax[0].tick_params(axis='both', which='major', labelsize=20)\n",
    "#ax[0].set_xticks(0])\n",
    "legend = ax[0].legend(fontsize = 14)\n",
    "legend.get_title().set_fontsize('18')\n",
    "\n",
    "ax[1].plot(ds,l1_inner, label ='l1 Inner', color = \"darkblue\", alpha = 0.5)\n",
    "ax[1].plot(ds,l1_outer, label ='l1 Outer', color = \"darkblue\", linestyle = 'dashed')\n",
    "ax[1].plot(ds,F_inner, label ='Frobenius Inner', color = \"red\", alpha = 0.5)\n",
    "ax[1].plot(ds,F_outer, label ='Frobenius Outer', color = \"red\", linestyle = 'dashed')\n",
    "ax[1].plot(ds,zo_inner, label ='One-Zero Inner', color = \"darkgreen\", alpha = 0.5)\n",
    "ax[1].plot(ds,zo_outer, label ='One-Zero Outer', color = \"darkgreen\", linestyle = 'dashed')\n",
    "#ax[1].plot(nr_admm_its,[np.mean(zo_error[i]) for i in range(len(zo_error))], label ='Zero-One')\n",
    "#ax[1].plot(nr_admm_its,[np.mean(f_error[i]) for i in range(len(f_error))], label ='Frobenius')\n",
    "legend = ax[1].legend(title = \"Metric\",fontsize = 14, bbox_to_anchor = (1.05,1))\n",
    "legend.get_title().set_fontsize('18')\n",
    "ax[1].set_xlabel(\"Nr. inner ADMM iterations\", fontdict = {'fontsize':24})\n",
    "ax[1].set_ylabel(\"Error\", fontdict = {'fontsize':24})\n",
    "ax[1].tick_params(axis='both', which='major', labelsize=20)\n",
    "# ax[1].set_xticks([0,5, 10, 15])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Fix an search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5559183673469388\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]C:\\Users/User/Code/DyGraph\\DyGraph\\dygl_parallel.py:109: UserWarning: EM algorithm did not converge. Try to increase number of iterations\n",
      "  warnings.warn(\"EM algorithm did not converge. Try to increase number of iterations\")\n",
      " 47%|████▋     | 47/100 [42:57<1:24:16, 95.40s/it]C:\\Users/User/Code/DyGraph\\DyGraph\\dygl_parallel.py:405: UserWarning: Max iterations reached.\n",
      "  warnings.warn(\"Max iterations reached.\")\n",
      " 65%|██████▌   | 65/100 [1:17:54<1:10:12, 120.36s/it]"
     ]
    }
   ],
   "source": [
    "d = 50\n",
    "alpha_prob =  0.8 #[0.03, 0.15, 0.5, 0.7, 0.8, 0.9, 0.95, 0.97, 0.99 ]\n",
    "alphas = np.linspace(0.01, 0.2, 10)\n",
    "kappas = np.linspace(0.01, 0.3, 10)\n",
    "tol = 1e-10\n",
    "n = 1000\n",
    "obs_per_graph = 100\n",
    "prec_dict ={}\n",
    "\n",
    "dens_inner = {i: [] for i in range(len(kappas))}\n",
    "time_inner = {i: [] for i in range(len(kappas))}\n",
    "F_inner = {i: [] for i in range(len(kappas))}\n",
    "zo_inner = {i: [] for i in range(len(kappas))}\n",
    "l1_inner = {i: [] for i in range(len(kappas))}\n",
    "\n",
    "dens_outer = {i: [] for i in range(len(kappas))}\n",
    "time_outer = {i: [] for i in range(len(kappas))}\n",
    "F_outer = {i: [] for i in range(len(kappas))}\n",
    "zo_outer = {i: [] for i in range(len(kappas))}\n",
    "l1_outer = {i: [] for i in range(len(kappas))}\n",
    "\n",
    "prec = make_sparse_spd_matrix(d, alpha=alpha_prob, smallest_coef=-0.9, largest_coef=0.9, norm_diag = True, random_state = 42)\n",
    "tmp = prec.copy()\n",
    "np.fill_diagonal(tmp,0)\n",
    "G = nx.from_numpy_array(tmp)\n",
    "print(nx.density(G))\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "X1 = mvt.rvs(shape = np.linalg.inv(prec),  df = 4, size = n) # np.random.multivariate_normal(mean = np.zeros(prec.shape[0]),cov = np.linalg.inv(prec), size = n)\n",
    "X = X1\n",
    "\n",
    "\n",
    "pbar = tqdm.tqdm(total = len(alphas)*len(kappas))\n",
    "\n",
    "for i, kappa in enumerate(kappas):\n",
    "    for alpha in alphas:\n",
    "\n",
    "\n",
    "\n",
    "        start = time.time()\n",
    "        dg_opt1 = dg.dygl_parallel(obs_per_graph = obs_per_graph, max_iter = 10000, lamda = obs_per_graph*alpha, kappa = obs_per_graph*kappa, tol = tol)\n",
    "        dg_opt1.fit(X, nr_workers=1, temporal_penalty=\"element-wise\", lik_type=\"t\", nr_em_itr = 1, time_index=range(X.shape[0]), nu = 4, em_tol = 1e-10, verbose =False)\n",
    "        elapsed = time.time()-start\n",
    "        dens_inner[i].append(nx.density(G))\n",
    "        time_inner[i].append(elapsed)\n",
    "\n",
    "        zo_inner[i].append(np.mean([calc_one_zero_error(prec, dg_opt1.theta[k]) for k in range(len(dg_opt1.theta))]))\n",
    "        F_inner[i].append(np.mean([scipy.linalg.norm(prec-dg_opt1.theta[k], ord = 'fro')/scipy.linalg.norm(prec, ord = 'fro') for k in range(len(dg_opt1.theta))]))\n",
    "        l1_inner[i].append(np.mean([scipy.linalg.norm(prec-dg_opt1.theta[k], ord = 1)/scipy.linalg.norm(prec, ord = 1) for k in range(len(dg_opt1.theta))]))\n",
    "            \n",
    "        start = time.time()\n",
    "        dg_opt1 = dg.dygl_parallel(obs_per_graph = obs_per_graph, max_iter = 10000, lamda = obs_per_graph*alpha, kappa = obs_per_graph*kappa, tol = tol)\n",
    "        dg_opt1.fit(X, nr_workers=1, temporal_penalty=\"element-wise\", lik_type=\"gaussian\", time_index=range(X.shape[0]), verbose =False)\n",
    "        elapsed = time.time()-start\n",
    "        dens_outer[i].append(nx.density(G))\n",
    "        time_outer[i].append(elapsed)\n",
    "\n",
    "        zo_outer[i].append(np.mean([calc_one_zero_error(prec, dg_opt1.theta[k]) for k in range(len(dg_opt1.theta))]))\n",
    "        F_outer[i].append(np.mean([scipy.linalg.norm(prec-dg_opt1.theta[k], ord = 'fro')/scipy.linalg.norm(prec, ord = 'fro') for k in range(len(dg_opt1.theta))]))\n",
    "        l1_outer[i].append(np.mean([scipy.linalg.norm(prec-dg_opt1.theta[k], ord = 1)/scipy.linalg.norm(prec, ord = 1) for k in range(len(dg_opt1.theta))]))\n",
    "\n",
    "        pbar.update()\n",
    "\n",
    "    out_dict = {'nr_obs_per_graph':obs_per_graph, 'n':n, 'temporal_penalty':'global-reconstruction', 'prec':prec,\n",
    "    'density_inner':dens_inner, 'tol':tol, 'time_inner':time_inner, 'zo_inner':zo_inner, 'F_inner':F_inner, 'l1_inner':l1_inner,\n",
    "    'density_outer':dens_outer,  'time_outer':time_outer, 'zo_outer':zo_outer, 'F_outer':F_outer, 'l1_outer':l1_outer,\n",
    "    'alpha':alphas, 'kappa':kappas, 'max_iter':5000} \n",
    "\n",
    "    import pickle\n",
    "    with open(f'../data/distributions/mvt_mvt_gaussian_search.pkl', 'wb') as handle:\n",
    "        pickle.dump(out_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DyGraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95fbe69513d588cbfb572e93f5d450d181f1d8d49af9eba3df43ef2e3376dba8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
